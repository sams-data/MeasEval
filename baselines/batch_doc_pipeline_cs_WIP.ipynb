{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from torch import nn\n",
    "from torch.optim import AdamW, Adam\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import RobertaModel\n",
    "from transformers import get_scheduler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "random.seed(42)\n",
    "reprocess_raw =  False\n",
    "\n",
    "batch_size = 10 # documents\n",
    "learning_rate = 5e-5\n",
    "n_epochs = 10\n",
    "\n",
    "# task_map = {'Quantity':1}\n",
    "task_map = {'Quantity':1,'MeasuredProperty':2,'MeasuredEntity':3,'Qualifier':4} # uncomment for multi-class\n",
    "num_classes = len(task_map)\n",
    "\n",
    "model_name = 'allenai/cs_roberta_base'\n",
    "# model_name = 'bert-base-cased'\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = 'cpu' # uncomment this to make debugging easier\n",
    "\n",
    "data_size_reduce = 1 # multiplier for making small datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentdir = os.getcwd() # ~/MeasEval/baselines\n",
    "\n",
    "combopath_txt = os.path.join(currentdir, \"../data/raw/combo/text/\")\n",
    "combopath_annot = os.path.join(currentdir, \"../data/raw/combo/tsv/\")\n",
    "\n",
    "interimpath = os.path.join(currentdir, \"../data/interim/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_txt(docs):\n",
    "    processesd_txt = {}\n",
    "    remove_markers = True\n",
    "\n",
    "    cnt_toks = {\"figs.\": 0, \"fig.\": 0, \"et al.\": 0,\n",
    "            \"ref.\": 0, \"eq.\": 0, \"e.g.\": 0,\n",
    "            \"i.e.\": 0, \"nos.\": 0, \"no.\": 0,\n",
    "            \"spp.\": 0\n",
    "            }\n",
    "    regex_end_checker = [\".*[a-zA-Z]figs\\.$\", \n",
    "                        \".*[a-zA-Z]fig\\.$\",\n",
    "                        \".*[a-zA-Z]et al\\.$\",\n",
    "                        \".*[a-zA-Z]ref\\.$\",\n",
    "                        \".*[a-zA-Z]eq\\.$\",\n",
    "                        \".*[a-zA-Z]e\\.g\\.$\",\n",
    "                        \".*[a-zA-Z]i\\.e\\.$\",\n",
    "                        \".*[a-zA-Z]nos\\.$\",\n",
    "                        \".*[a-zA-Z]no\\.$\",\n",
    "                        \".*[a-zA-Z]spp\\.$\",\n",
    "                        # figs., fig., et al., Ref., Eq., e.g., i.e., Nos., No., spp.\n",
    "                    ]\n",
    "\n",
    "    assert len(cnt_toks) == len(regex_end_checker)\n",
    "\n",
    "    for docId, doc in docs.items():\n",
    "        flag = False\n",
    "        sentences = sent_tokenize(doc)\n",
    "\n",
    "        fixed_sentence_tokens = []\n",
    "        curr_len = 0\n",
    "        for s in sentences:\n",
    "            if flag == True:\n",
    "                assert s[0] != ' '\n",
    "                white_length = doc[curr_len:].find(s[0])\n",
    "\n",
    "                prev_len = len(fixed_sentence_tokens[-1])\n",
    "                fixed_sentence_tokens[-1] = fixed_sentence_tokens[-1] + (\" \"*white_length) + s\n",
    "\n",
    "                assert fixed_sentence_tokens[-1][prev_len+white_length] == doc[curr_len+white_length], (fixed_sentence_tokens[-1], doc, curr_len, tmp_this_sent_len)\n",
    "                tmp_this_sent_len = white_length + len(s)\n",
    "                assert fixed_sentence_tokens[-1][-1] == doc[curr_len+tmp_this_sent_len-1], (fixed_sentence_tokens[-1], doc, curr_len, tmp_this_sent_len)\n",
    "                curr_len += tmp_this_sent_len\n",
    "            else:\n",
    "                if len(fixed_sentence_tokens) != 0:\n",
    "                    assert s[0] != ' '\n",
    "                    white_length = doc[curr_len:].find(s[0])\n",
    "                    fixed_sentence_tokens.append( (\" \"*white_length) + s )\n",
    "                else:\n",
    "                    fixed_sentence_tokens.append(s)\n",
    "                assert fixed_sentence_tokens[-1][0] == doc[curr_len], (fixed_sentence_tokens, doc, curr_len, tmp_this_sent_len)\n",
    "                tmp_this_sent_len = len(fixed_sentence_tokens[-1])\n",
    "                assert fixed_sentence_tokens[-1][-1] == doc[curr_len+tmp_this_sent_len-1], (fixed_sentence_tokens[-1], doc, curr_len, tmp_this_sent_len)\n",
    "                curr_len += tmp_this_sent_len\n",
    "\n",
    "            lower_cased_s = fixed_sentence_tokens[-1].lower()\n",
    "            flag = False\n",
    "            if remove_markers:\n",
    "                for i, k in enumerate(cnt_toks):\n",
    "                    this_regex_pattern = regex_end_checker[i]\n",
    "                    if lower_cased_s.endswith(k) and re.match(this_regex_pattern, lower_cased_s) == None:\n",
    "                        cnt_toks[k] += 1\n",
    "                        flag = True\n",
    "                        break\n",
    "\n",
    "        processesd_txt[docId] = ''.join(fixed_sentence_tokens)\n",
    "    return processesd_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(reprocess_raw = False):\n",
    "\n",
    "    if reprocess_raw == True:\n",
    "        docIds = []\n",
    "        combo_txt = {}\n",
    "        for fn in os.listdir(combopath_txt):\n",
    "            docIds.append(fn[:-4])\n",
    "            path = combopath_txt+fn\n",
    "            with open(path) as textfile:\n",
    "                    text = textfile.read()\n",
    "                    #[:-4] strips off the .txt to get the id\n",
    "                    combo_txt[fn[:-4]] = text\n",
    "\n",
    "        combo_annot = pd.DataFrame()\n",
    "        for fn in os.listdir(combopath_annot):\n",
    "            path = combopath_annot+fn\n",
    "            file = pd.read_csv(path,delimiter='\\t',encoding='utf-8')\n",
    "            combo_annot = pd.concat([combo_annot, file],ignore_index=True)\n",
    "\n",
    "        combo_txt = process_raw_txt(combo_txt)\n",
    "        assert docIds == list(combo_txt.keys()), (len(docIds), len(list(combo_txt.keys())))\n",
    "\n",
    "        with open(interimpath+'combo_txt.json','w') as f:\n",
    "            json.dump(combo_txt, f)\n",
    "\n",
    "        combo_annot.to_csv(interimpath+'combo_annot.csv')\n",
    "\n",
    "        return docIds, combo_txt, combo_annot\n",
    "    else:\n",
    "        combo_annot = pd.read_csv(interimpath+'combo_annot.csv')\n",
    "\n",
    "        with open(interimpath+'combo_txt.json','r') as f:\n",
    "            combo_txt = json.load(f)\n",
    "\n",
    "        docIds = list(combo_txt.keys())\n",
    "    \n",
    "        return docIds, combo_txt, combo_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_docs, combo_txt, combo_annot = read_data(reprocess_raw = reprocess_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### train/dev/test split options\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "percent_to_test = .1\n",
    "percent_to_dev = .2\n",
    "percent_to_train =  1 - percent_to_dev - percent_to_test\n",
    "\n",
    "n_doc = len(combo_docs)\n",
    "split_train = int(np.round(n_doc * percent_to_train))\n",
    "split_dev = split_train + int(np.round(n_doc * percent_to_dev))\n",
    "\n",
    "train_docs = combo_docs[:split_train]\n",
    "dev_docs = combo_docs[split_train:split_dev]\n",
    "test_docs = combo_docs[split_dev:]\n",
    "\n",
    "train_docs = random.sample(train_docs, int(len(train_docs)*data_size_reduce))\n",
    "dev_docs = random.sample(dev_docs, int(len(dev_docs)*data_size_reduce))\n",
    "test_docs = random.sample(test_docs, int(len(test_docs)*data_size_reduce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Tokenizer ###########\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docId</th>\n",
       "      <th>annotId</th>\n",
       "      <th>annotType</th>\n",
       "      <th>annotSpan</th>\n",
       "      <th>subSpanType</th>\n",
       "      <th>linkId</th>\n",
       "      <th>linkSpan</th>\n",
       "      <th>subSpan</th>\n",
       "      <th>unit</th>\n",
       "      <th>unitEncoded</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comboId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S175058361300203X-1542_T1-5</th>\n",
       "      <td>S175058361300203X-1542</td>\n",
       "      <td>T1-5</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[646, 653]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m/s</td>\n",
       "      <td>[119, 73, 29]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2213158213001253-2433_T1-4</th>\n",
       "      <td>S2213158213001253-2433</td>\n",
       "      <td>T1-4</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[555, 559]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>[207]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1359645413009816-2243_T2-3</th>\n",
       "      <td>S1359645413009816-2243</td>\n",
       "      <td>T2-3</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[499, 511]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T1-3</td>\n",
       "      <td>[515, 522]</td>\n",
       "      <td>[499, 522]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0032063312003054-2501_T1-2</th>\n",
       "      <td>S0032063312003054-2501</td>\n",
       "      <td>T1-2</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[66, 68]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'mods': ['IsCount']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0006322312001096-1253_T11-1</th>\n",
       "      <td>S0006322312001096-1253</td>\n",
       "      <td>T11-1</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[320, 328]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>years</td>\n",
       "      <td>[12857]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0012821X12004384-1640_T4-3</th>\n",
       "      <td>S0012821X12004384-1640</td>\n",
       "      <td>T4-3</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[1202, 1210]</td>\n",
       "      <td>HasProperty</td>\n",
       "      <td>T3-3</td>\n",
       "      <td>[1212, 1225]</td>\n",
       "      <td>[1202, 1225]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0167577X14001256-517_T1-5</th>\n",
       "      <td>S0167577X14001256-517</td>\n",
       "      <td>T1-5</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[557, 561]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>[207]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               docId annotId  \\\n",
       "comboId                                                        \n",
       "S175058361300203X-1542_T1-5   S175058361300203X-1542    T1-5   \n",
       "S2213158213001253-2433_T1-4   S2213158213001253-2433    T1-4   \n",
       "S1359645413009816-2243_T2-3   S1359645413009816-2243    T2-3   \n",
       "S0032063312003054-2501_T1-2   S0032063312003054-2501    T1-2   \n",
       "S0006322312001096-1253_T11-1  S0006322312001096-1253   T11-1   \n",
       "S0012821X12004384-1640_T4-3   S0012821X12004384-1640    T4-3   \n",
       "S0167577X14001256-517_T1-5     S0167577X14001256-517    T1-5   \n",
       "\n",
       "                                     annotType     annotSpan  subSpanType  \\\n",
       "comboId                                                                     \n",
       "S175058361300203X-1542_T1-5           Quantity    [646, 653]          NaN   \n",
       "S2213158213001253-2433_T1-4           Quantity    [555, 559]          NaN   \n",
       "S1359645413009816-2243_T2-3   MeasuredProperty    [499, 511]  HasQuantity   \n",
       "S0032063312003054-2501_T1-2           Quantity      [66, 68]          NaN   \n",
       "S0006322312001096-1253_T11-1          Quantity    [320, 328]          NaN   \n",
       "S0012821X12004384-1640_T4-3     MeasuredEntity  [1202, 1210]  HasProperty   \n",
       "S0167577X14001256-517_T1-5            Quantity    [557, 561]          NaN   \n",
       "\n",
       "                             linkId      linkSpan       subSpan   unit  \\\n",
       "comboId                                                                  \n",
       "S175058361300203X-1542_T1-5     NaN           NaN           NaN    m/s   \n",
       "S2213158213001253-2433_T1-4     NaN           NaN           NaN      %   \n",
       "S1359645413009816-2243_T2-3    T1-3    [515, 522]    [499, 522]    NaN   \n",
       "S0032063312003054-2501_T1-2     NaN           NaN           NaN    NaN   \n",
       "S0006322312001096-1253_T11-1    NaN           NaN           NaN  years   \n",
       "S0012821X12004384-1640_T4-3    T3-3  [1212, 1225]  [1202, 1225]    NaN   \n",
       "S0167577X14001256-517_T1-5      NaN           NaN           NaN      %   \n",
       "\n",
       "                                unitEncoded                   misc  \n",
       "comboId                                                             \n",
       "S175058361300203X-1542_T1-5   [119, 73, 29]                    NaN  \n",
       "S2213158213001253-2433_T1-4           [207]                    NaN  \n",
       "S1359645413009816-2243_T2-3             NaN                    NaN  \n",
       "S0032063312003054-2501_T1-2             NaN  {'mods': ['IsCount']}  \n",
       "S0006322312001096-1253_T11-1        [12857]                    NaN  \n",
       "S0012821X12004384-1640_T4-3             NaN                    NaN  \n",
       "S0167577X14001256-517_T1-5            [207]                    NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_annotation_set(annot_set):\n",
    "\n",
    "    annot_set_processed = []\n",
    "\n",
    "    annot_set['comboIds'] = annot_set[['docId','annotId']].agg('_'.join, axis=1)\n",
    "    annot_set.set_index('comboIds',inplace=True)\n",
    "\n",
    "    for comboId in list(annot_set.index):\n",
    "        \n",
    "        docId = annot_set.loc[comboId]['docId']\n",
    "        annotId = annot_set.loc[comboId]['annotId']\n",
    "\n",
    "        annotType = annot_set.loc[comboId]['annotType']\n",
    "        annotSpan = [annot_set.loc[comboId]['startOffset'],annot_set.loc[comboId]['endOffset']]\n",
    "\n",
    "        ent_annot_processed = {\n",
    "            'comboId':comboId,\n",
    "            'docId':docId,\n",
    "            'annotId':annotId,\n",
    "            'annotType':annotType,\n",
    "            'annotSpan':annotSpan,\n",
    "            'subSpanType':np.nan,\n",
    "            'linkId':np.nan,\n",
    "            'linkSpan':np.nan,\n",
    "            'subSpan':np.nan,\n",
    "            'unit':np.nan,\n",
    "            'unitEncoded':np.nan,\n",
    "            'misc':np.nan\n",
    "        }\n",
    "        \n",
    "        other = annot_set.loc[comboId]['other']\n",
    "        if isinstance(other,str):\n",
    "            otherDict = json.loads(str(other))\n",
    "\n",
    "            if annot_set.loc[comboId]['annotType'] != 'Quantity':\n",
    "\n",
    "                ent_annot_processed['subSpanType'] = list(otherDict.keys())[0]\n",
    "                link = list(otherDict.values())[0]\n",
    "\n",
    "                ent_annot_processed['linkId'] = link\n",
    "                linkIdx = docId+'_'+link\n",
    "                linkSpan = [int(annot_set.loc[linkIdx]['startOffset']),int(annot_set.loc[linkIdx]['endOffset'])]\n",
    "                ent_annot_processed['linkSpan'] = linkSpan\n",
    "\n",
    "                spanEnds = annotSpan + linkSpan\n",
    "                ent_annot_processed['subSpan'] = [min(spanEnds),max(spanEnds)]\n",
    "\n",
    "            elif 'unit' in list(otherDict.keys()):\n",
    "                unit = otherDict['unit']\n",
    "                ent_annot_processed['unit'] = unit\n",
    "                ent_annot_processed['unitEncoded'] = tokenizer.encode(unit)[1:-1]\n",
    "            else:\n",
    "                ent_annot_processed['misc'] = otherDict\n",
    "\n",
    "\n",
    "        annot_set_processed.append(ent_annot_processed)\n",
    "   \n",
    "    return pd.DataFrame.from_dict(annot_set_processed).set_index('comboId')\n",
    "\n",
    "combo_annot_processed = process_annotation_set(combo_annot)\n",
    "combo_annot_processed.to_csv(interimpath+'combo_annot_processed.csv')\n",
    "combo_annot_processed.sample(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert special tokens for subspans (Sam)\n",
    "# will make docs longer\n",
    "\n",
    "# def char_map(doc_annot, task_map)\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(\n",
    "                                doc_list=combo_docs,\n",
    "                                txt=combo_txt,\n",
    "                                processed_annotation=combo_annot_processed,\n",
    "                                tokenizer=tokenizer,\n",
    "                                taskLabelMap=task_map\n",
    "                            ):\n",
    "\n",
    "    toks_with_labels = []\n",
    "    special_ids = tokenizer.all_special_ids\n",
    "\n",
    "    for doc in doc_list:\n",
    "        # print(doc)\n",
    "        # print(processed_annotation.loc[processed_annotation['docId'] == doc])\n",
    "        doc_annot = processed_annotation.loc[processed_annotation['docId'] == doc]\n",
    "        doc_annot.set_index('annotId',inplace=True)\n",
    "        # print(doc_annot)\n",
    "\n",
    "        encoded_txt = tokenizer(txt[doc], padding='max_length', max_length=512, truncation=True)\n",
    "        encoded_tokens = encoded_txt['input_ids']\n",
    "        # print(encoded_tokens)\n",
    "\n",
    "        ############### Label Primary Spans ###############\n",
    "\n",
    "        labelIds = np.full(len(encoded_tokens),-1)\n",
    "        taskCharMap = {} # \n",
    "        taskCharList = []\n",
    "        taskAnnotIdCharMap = {} # to check for token collision\n",
    "        \n",
    "        for task in list(taskLabelMap.keys()):\n",
    "            #print(task)\n",
    "            annotId = doc_annot.loc[doc_annot['annotType']==task].index\n",
    "            # print(annotId)\n",
    "            spans = list(doc_annot.loc[doc_annot['annotType']==task]['annotSpan'])\n",
    "            # print(spans)\n",
    "            for span in spans:\n",
    "                # print(span)\n",
    "                span = list(range(span[0],span[-1]))\n",
    "                # print(span)\n",
    "                for spanCharIdx in span:\n",
    "                    # print(spanCharIdx)\n",
    "                    taskCharMap[spanCharIdx] = taskLabelMap[task]\n",
    "                # print(taskCharMap)\n",
    "                    # taskAnnotIdCharMap[spanCharIdx] = annotId\n",
    "\n",
    "        decoded = [''] * len(encoded_tokens)\n",
    "        for tokenIdx, token in enumerate(encoded_tokens):\n",
    "            \n",
    "            if token not in special_ids:\n",
    "                tokenCharStart = encoded_txt.token_to_chars(tokenIdx).start\n",
    "                if tokenCharStart in list(taskCharMap.keys()):\n",
    "                    labelIds[tokenIdx] = taskCharMap[tokenCharStart]\n",
    "                    decoded[tokenIdx] = tokenizer.decode(token)\n",
    "                else:\n",
    "                    labelIds[tokenIdx] = 0\n",
    "            else:\n",
    "                labelIds[tokenIdx] = 0\n",
    "        \n",
    "\n",
    "        ############### Sub Spans Token Insertion and labeling ###############\n",
    "\n",
    "        encoded_txt['doc_or_sent_id'] = doc\n",
    "        encoded_txt['labels'] = labelIds\n",
    "        \n",
    "        toks_with_labels.append(encoded_txt)\n",
    "    \n",
    "    # return toks_with_labels\n",
    "    return pd.DataFrame.from_dict(toks_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TOKENIZE #################\n",
    "\n",
    "stage1_train_ds = tokenize_and_align_labels(\n",
    "    doc_list=train_docs,\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_train_ds.to_csv(interimpath+'stage1_train_ds.csv')\n",
    "stage1_n_train = stage1_train_ds.shape[0]\n",
    "\n",
    "\n",
    "stage1_dev_ds = tokenize_and_align_labels(\n",
    "    doc_list=dev_docs,\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_dev_ds.to_csv(interimpath+'stage1_dev_ds.csv')\n",
    "stage1_n_dev = stage1_dev_ds.shape[0]\n",
    "\n",
    "stage1_test_ds = tokenize_and_align_labels(\n",
    "    doc_list=test_docs,\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_test_ds.to_csv(interimpath+'stage1_test_ds.csv')\n",
    "stage1_n_test = stage1_test_ds.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>doc_or_sent_id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0016236113008041-3290</td>\n",
       "      <td>[0, 44105, 4, 158, 924, 141, 821, 3175, 1827, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0006322312001096-1271</td>\n",
       "      <td>[0, 970, 32, 40833, 7, 5, 775, 431, 259, 4, 16...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0022000014000026-7850</td>\n",
       "      <td>[0, 170, 220, 6581, 5, 3280, 22744, 14, 32, 91...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103513005058-4158</td>\n",
       "      <td>[0, 170, 220, 146, 484, 10576, 7, 15756, 5, 11...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103512004009-4492</td>\n",
       "      <td>[0, 2709, 41, 16, 35941, 5466, 19, 10, 5181, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0012821X12004384-1232</td>\n",
       "      <td>[0, 1620, 820, 73, 698, 102, 12, 306, 16, 11, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0038071711004354-1624</td>\n",
       "      <td>[0, 1121, 645, 7, 1296, 5, 2513, 9, 5, 6594, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0168945213001805-4454</td>\n",
       "      <td>[0, 36439, 387, 354, 6335, 12236, 137, 5, 709,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S016412121300188X-4640</td>\n",
       "      <td>[0, 15248, 1342, 1437, 34, 65, 2778, 739, 2997...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 3, 3, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0168945213001805-4536</td>\n",
       "      <td>[0, 48313, 2356, 43122, 3488, 43164, 14170, 93...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        attention_mask  \\\n",
       "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "..                                                 ...   \n",
       "309  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "310  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "311  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "312  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "313  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "             doc_or_sent_id  \\\n",
       "0    S0016236113008041-3290   \n",
       "1    S0006322312001096-1271   \n",
       "2    S0022000014000026-7850   \n",
       "3    S0019103513005058-4158   \n",
       "4    S0019103512004009-4492   \n",
       "..                      ...   \n",
       "309  S0012821X12004384-1232   \n",
       "310  S0038071711004354-1624   \n",
       "311  S0168945213001805-4454   \n",
       "312  S016412121300188X-4640   \n",
       "313  S0168945213001805-4536   \n",
       "\n",
       "                                             input_ids  \\\n",
       "0    [0, 44105, 4, 158, 924, 141, 821, 3175, 1827, ...   \n",
       "1    [0, 970, 32, 40833, 7, 5, 775, 431, 259, 4, 16...   \n",
       "2    [0, 170, 220, 6581, 5, 3280, 22744, 14, 32, 91...   \n",
       "3    [0, 170, 220, 146, 484, 10576, 7, 15756, 5, 11...   \n",
       "4    [0, 2709, 41, 16, 35941, 5466, 19, 10, 5181, 2...   \n",
       "..                                                 ...   \n",
       "309  [0, 1620, 820, 73, 698, 102, 12, 306, 16, 11, ...   \n",
       "310  [0, 1121, 645, 7, 1296, 5, 2513, 9, 5, 6594, 1...   \n",
       "311  [0, 36439, 387, 354, 6335, 12236, 137, 5, 709,...   \n",
       "312  [0, 15248, 1342, 1437, 34, 65, 2778, 739, 2997...   \n",
       "313  [0, 48313, 2356, 43122, 3488, 43164, 14170, 93...   \n",
       "\n",
       "                                                labels  \n",
       "0    [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 0, ...  \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "309  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, ...  \n",
       "310  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "311  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "312  [0, 0, 0, 0, 0, 1, 0, 0, 3, 3, 0, 0, 1, 1, 1, ...  \n",
       "313  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[314 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage1_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>doc_or_sent_id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0022000014000026-7850</td>\n",
       "      <td>[0, 170, 220, 6581, 5, 3280, 22744, 14, 32, 91...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      attention_mask          doc_or_sent_id  \\\n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  S0022000014000026-7850   \n",
       "\n",
       "                                           input_ids  \\\n",
       "2  [0, 170, 220, 6581, 5, 3280, 22744, 14, 32, 91...   \n",
       "\n",
       "                                              labels  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stage1_train_ds[stage1_train_ds['doc_or_sent_id']=='S016412121300188X-4640']\n",
    "stage1_train_ds[stage1_train_ds['doc_or_sent_id']=='S0022000014000026-7850']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docId</th>\n",
       "      <th>annotId</th>\n",
       "      <th>annotType</th>\n",
       "      <th>annotSpan</th>\n",
       "      <th>subSpanType</th>\n",
       "      <th>linkId</th>\n",
       "      <th>linkSpan</th>\n",
       "      <th>subSpan</th>\n",
       "      <th>unit</th>\n",
       "      <th>unitEncoded</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comboId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [docId, annotId, annotType, annotSpan, subSpanType, linkId, linkSpan, subSpan, unit, unitEncoded, misc]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_annot_processed[combo_annot_processed['docId']=='S0022000014000026-7850']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_label = stage1_train_ds[stage1_train_ds['doc_or_sent_id']=='S016412121300188X-4640'][['labels']].values\n",
    "\n",
    "test_input_id = stage1_train_ds[stage1_train_ds['doc_or_sent_id']=='S016412121300188X-4640'][['input_ids']].values\n",
    "\n",
    "#not function only\n",
    "txt_encoding = np.array(test_input_id[0][0])\n",
    "lbls = test_label[0][0]\n",
    "\n",
    "lbls_ones = [0 if i>1 else i for i in lbls]\n",
    "testing = np.multiply(txt_encoding,lbls_ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 3, 3, 0, 0, 1, 1, 1, 1, 0, 0, 3, 3, 3, 3,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 1, 3, 3, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a list for unit encoded per document\n",
    "#dict for docid S016412121300188X-4640\n",
    "unit_encodings = [[7203], [13753], [119]]\n",
    "\n",
    "lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unit_encodings:\n",
    "    #testing\n",
    "    # condition, true action, false action\n",
    "    new_testing = np.where(testing == i, 5, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,   27,    0,    0,    0,    0,    0,\n",
       "          0, 3135,    4,  134,  207,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0, 4431,    0,\n",
       "          0,    0,  262,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "       4431,    0,    0,  973,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,  973,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4, 134, 207])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.asarray((4, 134, 207))\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = np.asarray([4, 134, 207])\n",
    "a = len(embeddings)\n",
    "indices = np.where(testing == embeddings[0])[0] # get array of indices matching first number\n",
    "#for x in embeddings:\n",
    "    \n",
    "print(indices)\n",
    "\n",
    "#check if the embedding matches\n",
    "\n",
    "for i in indices:\n",
    "    if testing[i:i+a].all() == embeddings.all():\n",
    "        testing[i:i+a] = np.full((1, a), 400000000)\n",
    "    else:\n",
    "        continue\n",
    "replace_label = np.where(testing == 400000000, 4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        0,         0,         0,         0,         0,        65,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "            3135, 400000000, 400000000, 400000000,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,      4431,         0,         0,         0,       262,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,      4431,         0,         0,       973,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,       973,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0,         0,         0,         0,         0,\n",
       "               0,         0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# marks unit encoding with a 4, otherwise 0\n",
    "replace_label = np.where(testing == 207, 4, 0)\n",
    "replace_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add vector to original labels so that units are now marked as 5\n",
    "new_label = np.add(replace_label, lbls)\n",
    "new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input_list = input_ids\n",
    "labels_list = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stage1_train_ds[:1]['labels'][0])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>doc_or_sent_id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103512004009-4492</td>\n",
       "      <td>[0, 2709, 41, 16, 35941, 5466, 19, 10, 5181, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103512002801-1342</td>\n",
       "      <td>[0, 500, 26343, 16, 25012, 17, 27, 29, 1154, 2...</td>\n",
       "      <td>[0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0016236113008041-3171</td>\n",
       "      <td>[0, 44105, 4, 231, 924, 5, 26069, 9, 3694, 478...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0378383912000130-1096</td>\n",
       "      <td>[0, 14699, 12, 22760, 9, 1421, 12, 37466, 1979...</td>\n",
       "      <td>[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0016236113008041-2924</td>\n",
       "      <td>[0, 104, 40275, 1966, 2584, 66, 15, 14077, 482...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0925443913001385-1429</td>\n",
       "      <td>[0, 33837, 3024, 19961, 1001, 3662, 13651, 58,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0167278913001450-12425</td>\n",
       "      <td>[0, 44105, 4, 132, 924, 10, 5204, 15694, 15566...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 2, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0012821X12004384-1148</td>\n",
       "      <td>[0, 45311, 1022, 3059, 19, 5, 37527, 42416, 23...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0006322312001096-626</td>\n",
       "      <td>[0, 26039, 41156, 10414, 27335, 20117, 12366, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 1, 1, 2, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0016236113008041-3112</td>\n",
       "      <td>[0, 133, 45033, 20424, 5448, 21, 15050, 11, 10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103512004009-3976</td>\n",
       "      <td>[0, 133, 1683, 9, 2992, 5, 11545, 5838, 15, 5,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103513005058-1737</td>\n",
       "      <td>[0, 9157, 6342, 27748, 9, 41871, 11, 6507, 661...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0301010413004096-693</td>\n",
       "      <td>[0, 44791, 2383, 34098, 7208, 36, 8756, 597, 4...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0006322312001096-1275</td>\n",
       "      <td>[0, 15243, 10, 239, 1263, 7, 5, 2658, 36, 9435...</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0378383912000130-3827</td>\n",
       "      <td>[0, 1121, 5709, 7, 5, 112, 4, 245, 15408, 4105...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103512003995-2681</td>\n",
       "      <td>[0, 133, 40002, 672, 9, 5, 40150, 1421, 16, 55...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       attention_mask  \\\n",
       "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "5   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "11  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "13  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "14  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "15  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "16  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "17  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "18  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "19  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "             doc_or_sent_id  \\\n",
       "4    S0019103512004009-4492   \n",
       "5    S0019103512002801-1342   \n",
       "6    S0016236113008041-3171   \n",
       "7    S0378383912000130-1096   \n",
       "8    S0016236113008041-2924   \n",
       "9    S0925443913001385-1429   \n",
       "10  S0167278913001450-12425   \n",
       "11   S0012821X12004384-1148   \n",
       "12    S0006322312001096-626   \n",
       "13   S0016236113008041-3112   \n",
       "14   S0019103512004009-3976   \n",
       "15   S0019103513005058-1737   \n",
       "16    S0301010413004096-693   \n",
       "17   S0006322312001096-1275   \n",
       "18   S0378383912000130-3827   \n",
       "19   S0019103512003995-2681   \n",
       "\n",
       "                                            input_ids  \\\n",
       "4   [0, 2709, 41, 16, 35941, 5466, 19, 10, 5181, 2...   \n",
       "5   [0, 500, 26343, 16, 25012, 17, 27, 29, 1154, 2...   \n",
       "6   [0, 44105, 4, 231, 924, 5, 26069, 9, 3694, 478...   \n",
       "7   [0, 14699, 12, 22760, 9, 1421, 12, 37466, 1979...   \n",
       "8   [0, 104, 40275, 1966, 2584, 66, 15, 14077, 482...   \n",
       "9   [0, 33837, 3024, 19961, 1001, 3662, 13651, 58,...   \n",
       "10  [0, 44105, 4, 132, 924, 10, 5204, 15694, 15566...   \n",
       "11  [0, 45311, 1022, 3059, 19, 5, 37527, 42416, 23...   \n",
       "12  [0, 26039, 41156, 10414, 27335, 20117, 12366, ...   \n",
       "13  [0, 133, 45033, 20424, 5448, 21, 15050, 11, 10...   \n",
       "14  [0, 133, 1683, 9, 2992, 5, 11545, 5838, 15, 5,...   \n",
       "15  [0, 9157, 6342, 27748, 9, 41871, 11, 6507, 661...   \n",
       "16  [0, 44791, 2383, 34098, 7208, 36, 8756, 597, 4...   \n",
       "17  [0, 15243, 10, 239, 1263, 7, 5, 2658, 36, 9435...   \n",
       "18  [0, 1121, 5709, 7, 5, 112, 4, 245, 15408, 4105...   \n",
       "19  [0, 133, 40002, 672, 9, 5, 40150, 1421, 16, 55...   \n",
       "\n",
       "                                               labels  \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5   [0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, ...  \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, ...  \n",
       "7   [0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...  \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, ...  \n",
       "10  [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 2, 1, 1, ...  \n",
       "11  [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "12  [0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 1, 1, 2, 0, 0, ...  \n",
       "13  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "14  [0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "15  [0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, ...  \n",
       "16  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17  [0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 1, 1, 1, 1, 1, ...  \n",
       "18  [0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, ...  \n",
       "19  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teest_ds = stage1_train_ds[4:20]\n",
    "teest_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict_unit_encoded(dataframe):\n",
    "    df = dataframe\n",
    "    unique_docIds = list(df.docId.unique())\n",
    "    dict_unit_encodings = {}\n",
    "\n",
    "    for docId in unique_docIds:\n",
    "        list_unit_encodings = list(df.loc[df['docId']==docId]['unitEncoded'].dropna())\n",
    "        tup_unit_encodings = [tuple(i) for i in list_unit_encodings]\n",
    "        dict_unit_encodings[docId] = list(set(tup_unit_encodings))\n",
    "\n",
    "    return dict_unit_encodings\n",
    "\n",
    "\n",
    "unit_encodings_per_docId = make_dict_unit_encoded(combo_annot_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12857,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_encodings_per_docId['S0006322312001096-1136'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S0006322312001096-1136': [(42038, 3277), (12857,), (207,)],\n",
       " 'S0006322312001096-1177': [(2262,), (32198, 5421), (12857,), (22197,)],\n",
       " 'S0006322312001096-1190': [(5471, 1168, 73, 574),\n",
       "  (571,),\n",
       "  (12938, 347),\n",
       "  (207,),\n",
       "  (4691, 11282),\n",
       "  (21719,),\n",
       "  (4509,)],\n",
       " 'S0006322312001096-1194': [(207,)],\n",
       " 'S0006322312001096-1197': [(42038, 3277), (36907,), (207,)],\n",
       " 'S0006322312001096-1202': [(15725, 12023, 3082, 3597),\n",
       "  (2300,),\n",
       "  (207,),\n",
       "  (46740,),\n",
       "  (7033,),\n",
       "  (1208,)],\n",
       " 'S0006322312001096-1205': [(7033,)],\n",
       " 'S0006322312001096-1221': [(207,)],\n",
       " 'S0006322312001096-1230': [(180,), (207,)],\n",
       " 'S0006322312001096-1248': [(207,)],\n",
       " 'S0006322312001096-1253': [(12857,)],\n",
       " 'S0006322312001096-1260': [(180,), (12857,)],\n",
       " 'S0006322312001096-1271': [(242, 13034, 352, 3597), (207,)],\n",
       " 'S0006322312001096-1275': [(207,)],\n",
       " 'S0006322312001096-1278': [(12857,)],\n",
       " 'S0006322312001096-626': [],\n",
       " 'S0012821X12004384-1148': [(12938, 487), (39542,), (25447,)],\n",
       " 'S0012821X12004384-1178': [(17, 7487), (12938, 347), (2348,), (25447,)],\n",
       " 'S0012821X12004384-1221': [(119,), (7203,)],\n",
       " 'S0012821X12004384-1232': [(13753,), (119,), (7203,)],\n",
       " 'S0012821X12004384-1249': [(119,),\n",
       "  (642, 18022, 228, 15408),\n",
       "  (5471,),\n",
       "  (13562, 36645)],\n",
       " 'S0012821X12004384-1265': [(47049, 119), (571,), (207,)],\n",
       " 'S0012821X12004384-1284': [(298,),\n",
       "  (705, 73, 705),\n",
       "  (47049, 119),\n",
       "  (17, 7487),\n",
       "  (207,)],\n",
       " 'S0012821X12004384-1302': [(119,)],\n",
       " 'S0012821X12004384-1405': [(207,)],\n",
       " 'S0012821X12004384-1415': [(119,), (207,)],\n",
       " 'S0012821X12004384-1594': [(12938, 487), (119,)],\n",
       " 'S0012821X12004384-1599': [(119,), (39542,)],\n",
       " 'S0012821X12004384-1610': [(119,)],\n",
       " 'S0012821X12004384-1640': [(119,), (17, 7487), (139, 487)],\n",
       " 'S0012821X12004384-952': [(119,), (207,)],\n",
       " 'S0012821X12004384-990': [(119,), (207,)],\n",
       " 'S0012821X13002185-1061': [(180,), (2348,), (207,), (25447,)],\n",
       " 'S0012821X13002185-1200': [(47049, 574), (47049, 119)],\n",
       " 'S0012821X13002185-1217': [(3583,),\n",
       "  (17, 7487),\n",
       "  (10815,),\n",
       "  (4691,),\n",
       "  (12938, 347),\n",
       "  (448,),\n",
       "  (207,),\n",
       "  (642, 725)],\n",
       " 'S0012821X13002185-1231': [(17, 7487), (47049, 119), (207,)],\n",
       " 'S0012821X13002185-835': [(119,)],\n",
       " 'S0012821X13002185-994': [(17, 7487), (207,), (25447,)],\n",
       " 'S0012821X13007309-1482': [(13753,), (119,), (25447,)],\n",
       " 'S0012821X13007309-1509': [(119,), (17, 7487)],\n",
       " 'S0012821X13007309-1605': [(119,), (12938, 487), (119, 7992)],\n",
       " 'S0012821X13007309-1649': [(119,), (17, 7487), (119, 4311, 506)],\n",
       " 'S0012821X13007309-1691': [(119,), (17, 7487)],\n",
       " 'S0012821X13007309-1989': [(3807, 90), (207,), (14616,), (3807, 1343)],\n",
       " 'S0016236113008041-2924': [],\n",
       " 'S0016236113008041-3012': [(330, 771), (207,)],\n",
       " 'S0016236113008041-3031': [(3807, 119)],\n",
       " 'S0016236113008041-3112': [(207,)],\n",
       " 'S0016236113008041-3127': [(12938, 347)],\n",
       " 'S0016236113008041-3153': [(3807, 119), (9043,)],\n",
       " 'S0016236113008041-3159': [(9043,)],\n",
       " 'S0016236113008041-3161': [(3807, 119), (9043,)],\n",
       " 'S0016236113008041-3171': [(3807, 119), (9043,)],\n",
       " 'S0016236113008041-3186': [(3807, 119), (9043,)],\n",
       " 'S0016236113008041-3207': [(207,)],\n",
       " 'S0016236113008041-3257': [(9043,), (207,), (4301, 207)],\n",
       " 'S0016236113008041-3269': [(3807, 119)],\n",
       " 'S0016236113008041-3290': [(3807, 119)],\n",
       " 'S0016236113008041-872': [(9043,)],\n",
       " 'S0016236113008041-890': [(9043,)],\n",
       " 'S0016236113008041-913': [(3807, 119), (9043,)],\n",
       " 'S0016236113008041-961': [(207,)],\n",
       " 'S0016236113008041-967': [(9043,)],\n",
       " 'S0019103511004994-1382': [],\n",
       " 'S0019103511004994-1399': [(29918, 8629, 13206, 4132, 15388), (7203,)],\n",
       " 'S0019103511004994-1511': [(12938,), (29,), (5096, 846), (14616,)],\n",
       " 'S0019103511004994-1565': [(4691,), (1071, 846)],\n",
       " 'S0019103511004994-1607': [(12938,), (7203,), (1071, 846)],\n",
       " 'S0019103511004994-996': [(207,)],\n",
       " 'S0019103512001388-1070': [(4691,), (7033,), (6972,)],\n",
       " 'S0019103512001388-3081': [(207,)],\n",
       " 'S0019103512002801-1342': [(18591,), (7203,), (25733, 298)],\n",
       " 'S0019103512002801-1496': [(29,), (14616,)],\n",
       " 'S0019103512002801-1608': [(7203, 579, 47677, 134)],\n",
       " 'S0019103512002801-1716': [(282, 565)],\n",
       " 'S0019103512002801-1781': [(12938,), (29,), (1071, 846)],\n",
       " 'S0019103512002801-1824': [(207,)],\n",
       " 'S0019103512002801-1849': [(1071, 846), (207,)],\n",
       " 'S0019103512002801-1927': [(29,), (25733, 298), (29, 47677, 134)],\n",
       " 'S0019103512002801-2018': [(207,)],\n",
       " 'S0019103512002801-2075': [(7203,), (1071, 846)],\n",
       " 'S0019103512003533-3299': [(207,)],\n",
       " 'S0019103512003533-3306': [(530,)],\n",
       " 'S0019103512003533-3348': [(12938,), (29,), (8056, 16889)],\n",
       " 'S0019103512003533-3908': [(13753, 246, 579, 47677, 134)],\n",
       " 'S0019103512003533-4685': [(12938,), (7203,)],\n",
       " 'S0019103512003533-4971': [(530,)],\n",
       " 'S0019103512003533-5031': [(12938, 487), (530,)],\n",
       " 'S0019103512003533-5072': [(12938,), (119, 579, 47677, 134)],\n",
       " 'S0019103512003533-5211': [(12938,), (530,), (1071, 846), (6648, 271)],\n",
       " 'S0019103512003533-5251': [(530,)],\n",
       " 'S0019103512003533-5300': [(242, 846),\n",
       "  (1071, 846),\n",
       "  (119, 771, 475, 47677, 176),\n",
       "  (119, 846, 475, 47677, 134),\n",
       "  (530,)],\n",
       " 'S0019103512003533-5318': [(119, 771, 475, 47677, 176),\n",
       "  (530,),\n",
       "  (119, 846, 475, 47677, 134),\n",
       "  (1071, 846)],\n",
       " 'S0019103512003533-5598': [(12938, 104), (530,)],\n",
       " 'S0019103512003995-1237': [(7203, 579, 47677, 134),\n",
       "  (500,),\n",
       "  (119, 47677, 176)],\n",
       " 'S0019103512003995-1283': [(530,)],\n",
       " 'S0019103512003995-1767': [(28235,)],\n",
       " 'S0019103512003995-1807': [(28235,), (6648, 271)],\n",
       " 'S0019103512003995-1910': [(298,), (7033,), (2151,), (207,)],\n",
       " 'S0019103512003995-2096': [(500, 642), (530,), (47049, 4901)],\n",
       " 'S0019103512003995-2579': [(530,), (246, 500, 642)],\n",
       " 'S0019103512003995-2681': [(500, 642), (530,), (207,)],\n",
       " 'S0019103512003995-2737': [(9043, 579, 47677, 134), (530,), (14616,), (207,)],\n",
       " 'S0019103512003995-2760': [(7203, 579, 47677, 134), (500, 642)],\n",
       " 'S0019103512003995-3548': [(530,), (47049, 4901)],\n",
       " 'S0019103512004009-2821': [(500, 642), (530,), (47049, 4901), (22983,)],\n",
       " 'S0019103512004009-3488': [(530,), (47049, 4901), (6648, 271)],\n",
       " 'S0019103512004009-3825': [(500, 642), (530,), (207,), (282, 4901)],\n",
       " 'S0019103512004009-3962': [(530,), (47049, 4901), (14616,)],\n",
       " 'S0019103512004009-3976': [(7203, 579, 47677, 134), (500, 642), (6230,)],\n",
       " 'S0019103512004009-4007': [(242, 846), (207,)],\n",
       " 'S0019103512004009-4350': [(530,)],\n",
       " 'S0019103512004009-4492': [(7203, 579, 47677, 134),\n",
       "  (500, 642),\n",
       "  (530,),\n",
       "  (119, 725)],\n",
       " 'S0019103512004009-5019': [(771, 475, 47677, 176),\n",
       "  (530,),\n",
       "  (242, 846),\n",
       "  (282, 4901)],\n",
       " 'S0019103512004009-5033': [(47049, 4901),\n",
       "  (207,),\n",
       "  (500, 642),\n",
       "  (282, 4901),\n",
       "  (530,)],\n",
       " 'S0019103512004009-5271': [(500, 642),\n",
       "  (9043, 29, 12, 134),\n",
       "  (9043, 579, 47677, 134)],\n",
       " 'S0019103512004009-5507': [(500, 642), (530,), (47049, 4901)],\n",
       " 'S0019103513005058-1737': [(571, 25434, 47677, 246), (119,)],\n",
       " 'S0019103513005058-3094': [(119,), (43192, 4, 207), (207,), (1409, 338)],\n",
       " 'S0019103513005058-3154': [(14616,),\n",
       "  (43192, 4, 207),\n",
       "  (207,),\n",
       "  (3807, 119, 30, 2862)],\n",
       " 'S0019103513005058-3189': [(12938, 347), (571,)],\n",
       " 'S0019103513005058-3917': [(29, 47677, 134)],\n",
       " 'S0019103513005058-4098': [(530,), (207,)],\n",
       " 'S0019103513005058-4158': [(571, 25434, 47677, 246), (119,)],\n",
       " 'S0019103513005058-4175': [(6342, 38983), (43192, 4, 207), (207,)],\n",
       " 'S0019103513005058-4210': [(43192, 4, 7606), (119,)],\n",
       " 'S0019103513005058-4302': [(119,), (43192, 4, 207), (1409, 338)],\n",
       " 'S0019103513005058-4349': [(28436, 9, 11259), (207,)],\n",
       " 'S0019103513005058-4499': [(530,)],\n",
       " 'S0021979713004438-1401': [(12938,), (846,), (43192, 4, 207), (207,)],\n",
       " 'S0021979713004438-1415': [(12938, 347)],\n",
       " 'S0021979713004438-1907': [(4691,), (47049, 119)],\n",
       " 'S0021979713004438-1969': [(642, 725), (207,), (28235,), (47049, 448)],\n",
       " 'S0021979713004438-2004': [(7629, 102)],\n",
       " 'S0021979713004438-2148': [(4691,), (47049, 448), (13753, 47677, 134)],\n",
       " 'S0022000014000026-12523': [],\n",
       " 'S0022000014000026-17824': [(47049, 29)],\n",
       " 'S0022000014000026-18167': [(5881,), (207,)],\n",
       " 'S0022399913003358-1044': [(180,), (207,)],\n",
       " 'S0022399913003358-931': [(180,), (12857,), (207,)],\n",
       " 'S0022399913003358-943': [(42038, 3277), (207,)],\n",
       " 'S0022399913003358-956': [(12857,)],\n",
       " 'S0022459611006116-1160': [(207,)],\n",
       " 'S0022459611006116-1195': [(12938,), (4691,)],\n",
       " 'S0022459611006116-1200': [(12938,), (298,)],\n",
       " 'S0022459611006116-1257': [(12938,),\n",
       "  (40523,),\n",
       "  (530,),\n",
       "  (43192, 207),\n",
       "  (3849, 5782)],\n",
       " 'S0022459611006116-1351': [(530,), (3849, 5782)],\n",
       " 'S0022459611006116-1448': [(530,)],\n",
       " 'S0022459611006116-547': [(530,)],\n",
       " 'S0022459611006116-987': [(530,)],\n",
       " 'S0025322712001600-2230': [(12857,)],\n",
       " 'S0025322712001600-2406': [(119,), (207,)],\n",
       " 'S0031405612000728-1621': [(34606,), (2151,)],\n",
       " 'S0031405612000728-1639': [(7033,), (1208,)],\n",
       " 'S0031405612000728-769': [],\n",
       " 'S0032063312000487-1141': [(207,)],\n",
       " 'S0032063312002437-586': [(7203,)],\n",
       " 'S0032063312002437-593': [(4691,), (12938, 487), (7203,)],\n",
       " 'S0032063312002437-627': [(29,), (6972,)],\n",
       " 'S0032063312003054-1990': [(4691,), (242, 846)],\n",
       " 'S0032063312003054-2264': [(242, 846), (7203,)],\n",
       " 'S0032063312003054-2458': [(207,)],\n",
       " 'S0032063312003054-2467': [(207,)],\n",
       " 'S0032063312003054-2483': [(6972,)],\n",
       " 'S0032063312003054-2501': [(207,)],\n",
       " 'S0032063313003218-5227': [(530,), (12857,)],\n",
       " 'S0032063313003218-5269': [(119, 771, 475, 47677, 176), (530,), (207,)],\n",
       " 'S0032063313003218-5381': [(7033,), (4691, 11282)],\n",
       " 'S0032063313003218-6078': [(298,)],\n",
       " 'S0032063313003218-6651': [(12938,),\n",
       "  (330, 500),\n",
       "  (119, 771, 119, 47677, 176),\n",
       "  (12938, 36961)],\n",
       " 'S0032063313003218-7156': [(207,), (29334,)],\n",
       " 'S0032063313003218-7389': [(298,)],\n",
       " 'S0032386113005454-1245': [(12938, 347), (43192, 207)],\n",
       " 'S0032386113005454-1270': [(12938, 347)],\n",
       " 'S0032386113005454-2008': [(12938, 347)],\n",
       " 'S0032386113005454-2022': [(47049, 119), (207,)],\n",
       " 'S0032386113005454-2055': [(37825,),\n",
       "  (12938, 347),\n",
       "  (12938, 347, 73, 4691),\n",
       "  (571, 73, 119, 246),\n",
       "  (5471, 246)],\n",
       " 'S0032386113005454-2308': [(43192, 207), (12694, 102)],\n",
       " 'S0032386113005454-2601': [(7629, 102), (12938, 347), (43192, 207)],\n",
       " 'S0032386113005454-2865': [(12938, 347), (47049, 119), (207,)],\n",
       " 'S0032386113005454-2876': [(12938, 347)],\n",
       " 'S0032386113005454-2886': [(12938, 347)],\n",
       " 'S0032386113009889-2123': [(7629, 102)],\n",
       " 'S0038071711004354-1624': [(13753,), (34606,), (4691,)],\n",
       " 'S0038071711004354-1644': [(13753,), (12938, 347), (207,), (5471,), (119,)],\n",
       " 'S0038071711004354-2370': [(207,)],\n",
       " 'S0038071711004354-2389': [(571,\n",
       "   6247,\n",
       "   176,\n",
       "   475,\n",
       "   47677,\n",
       "   176,\n",
       "   1368,\n",
       "   47677,\n",
       "   134),\n",
       "  (207,)],\n",
       " 'S0038071711004354-2573': [(13753,)],\n",
       " 'S0038071711004354-2578': [(13753,)],\n",
       " 'S0038071711004354-755': [(298,), (17, 7487)],\n",
       " 'S0038071712001010-1044': [(7033,), (5471, 176)],\n",
       " 'S0038071712001010-918': [(207,)],\n",
       " 'S0038071712001010-944': [(207,)],\n",
       " 'S0038071713001971-1388': [(207,)],\n",
       " 'S0038071713001971-1427': [(12857,)],\n",
       " 'S016412121300188X-3207': [(207,), (530, 25419, 347)],\n",
       " 'S016412121300188X-4069': [(11723, 9, 3260),\n",
       "  (207,),\n",
       "  (6243, 534, 33566, 6355)],\n",
       " 'S016412121300188X-4207': [(207,)],\n",
       " 'S016412121300188X-4392': [(207,)],\n",
       " 'S016412121300188X-4436': [(207,)],\n",
       " 'S016412121300188X-4545': [(9942, 6355), (207,)],\n",
       " 'S016412121300188X-4617': [(207,)],\n",
       " 'S016412121300188X-4640': [(207,)],\n",
       " 'S016412121300188X-4937': [(207,)],\n",
       " 'S016412121300188X-5038': [],\n",
       " 'S016412121300188X-5066': [(207,)],\n",
       " 'S0165587612003680-1078': [(23462, 38258), (207,)],\n",
       " 'S0165587612003680-953': [(207,)],\n",
       " 'S0165587612003680-998': [(207,)],\n",
       " 'S0167278913001450-12425': [(119,)],\n",
       " 'S0167577X13006393-399': [(13753, 47677, 134)],\n",
       " 'S0167577X13006393-644': [(12938, 347)],\n",
       " 'S0167577X13006393-662': [(330, 846), (18517, 73, 298), (18517,)],\n",
       " 'S0167577X13006393-787': [(12938, 347)],\n",
       " 'S0167577X13006393-801': [(12938, 347), (28235,)],\n",
       " 'S0167577X14001256-389': [(28235,)],\n",
       " 'S0167577X14001256-517': [(282, 863), (330, 846), (207,), (530,), (46858,)],\n",
       " 'S0167610512002292-3187': [(119,)],\n",
       " 'S0167610512002292-3305': [(119, 73, 29), (7203, 73, 298), (9043,)],\n",
       " 'S0167610513001001-1566': [(207,)],\n",
       " 'S0167610513001001-1618': [(119,), (119, 579, 47677, 134)],\n",
       " 'S0167610513001001-1751': [(119, 579, 47677, 134)],\n",
       " 'S0167610513001001-1769': [(12938,), (119, 579, 47677, 134), (4691,)],\n",
       " 'S0167610513001001-739': [(119,), (119, 579, 47677, 134)],\n",
       " 'S0167610513001001-858': [(4691,)],\n",
       " 'S0167610513002729-1062': [(725,)],\n",
       " 'S0167610513002729-1127': [(12938,), (725,)],\n",
       " 'S0167739X12001525-6016': [(207,)],\n",
       " 'S0167819113001051-1247': [(438, 4765), (207,)],\n",
       " 'S0167819113001051-1550': [(207,)],\n",
       " 'S0167880913001229-1021': [(13753,), (207,)],\n",
       " 'S0167880913001229-1033': [(13753,)],\n",
       " 'S0167880913001229-1225': [(13753,), (180,)],\n",
       " 'S0167880913001229-1304': [(13753,),\n",
       "  (448, 571, 2489, 47677, 134, 76, 47677, 134)],\n",
       " 'S0167880913001229-1323': [(13753,)],\n",
       " 'S0168945213001805-3964': [(20794,), (207,)],\n",
       " 'S0168945213001805-4454': [(180,), (207,)],\n",
       " 'S0168945213001805-4536': [(207,)],\n",
       " 'S0168945213001805-4574': [(207,)],\n",
       " 'S0168945213001805-4775': [(12938, 347)],\n",
       " 'S0168945213001805-5026': [(207,), (180, 12, 279)],\n",
       " 'S0168945213001805-5396': [(180,), (207,)],\n",
       " 'S0169433213008933-689': [(29,), (119, 14507), (47602,)],\n",
       " 'S0257897213007573-555': [(12938, 347)],\n",
       " 'S0257897213007573-574': [(47049, 119, 176), (28235,)],\n",
       " 'S0257897213007573-899': [(13753, 47677, 112), (28235,)],\n",
       " 'S0257897213007573-959': [(47049, 119), (28235,)],\n",
       " 'S027737911400050X-2401': [(2348,), (12857,)],\n",
       " 'S0301010413004096-646': [(530,)],\n",
       " 'S0301010413004096-693': [(530,), (43192, 207)],\n",
       " 'S0301010413004096-767': [(571,),\n",
       "  (1794, 846),\n",
       "  (12938, 347),\n",
       "  (207,),\n",
       "  (207, 48543, 717, 73, 717),\n",
       "  (1208,),\n",
       "  (530,),\n",
       "  (6648, 271)],\n",
       " 'S030881461301604X-1001': [(207,)],\n",
       " 'S030881461301604X-1002': [(22984, 73, 574), (47049, 571, 73, 574), (207,)],\n",
       " 'S0378112713005288-1720': [(119,), (40859, 29, 73, 1999)],\n",
       " 'S0378112713005288-1800': [(13753,), (119,), (207,)],\n",
       " 'S0378112713005288-1916': [(119,)],\n",
       " 'S0378112713005288-1948': [(207,)],\n",
       " 'S0378112713005288-2036': [(119,)],\n",
       " 'S0378112713005288-2062': [(9043,)],\n",
       " 'S0378383911001669-1088': [(119,), (5471,)],\n",
       " 'S0378383911001669-1112': [(5471,)],\n",
       " 'S0378383911001669-1203': [(119,), (5471,)],\n",
       " 'S0378383911001669-1634': [(22984, 73, 462), (5471,)],\n",
       " 'S0378383911001669-2205': [(119,), (5471,), (29,)],\n",
       " 'S0378383911001669-2260': [(119,), (5471,), (207,)],\n",
       " 'S0378383912000130-1041': [(5471,)],\n",
       " 'S0378383912000130-1048': [(5471,)],\n",
       " 'S0378383912000130-1054': [(5471,)],\n",
       " 'S0378383912000130-1090': [(5471,)],\n",
       " 'S0378383912000130-1096': [(5471,)],\n",
       " 'S0378383912000130-3601': [(5471,), (1610, 1488, 3183)],\n",
       " 'S0378383912000130-3662': [(5471,)],\n",
       " 'S0378383912000130-3726': [(5471,)],\n",
       " 'S0378383912000130-3732': [(5471,)],\n",
       " 'S0378383912000130-3739': [(29,), (5471,)],\n",
       " 'S0378383912000130-3745': [(5471,)],\n",
       " 'S0378383912000130-3755': [(5471,)],\n",
       " 'S0378383912000130-3827': [(5471,)],\n",
       " 'S0378383912000130-3891': [(5471,)],\n",
       " 'S0378383912000130-3907': [(5471,)],\n",
       " 'S0378383913001567-2462': [(13753,), (37825,)],\n",
       " 'S0378383913001567-6892': [(12938,), (119,)],\n",
       " 'S0378383913001567-7073': [(119,)],\n",
       " 'S037842901300244X-1427': [(207,)],\n",
       " 'S037842901300244X-1654': [(417, 281), (207,)],\n",
       " 'S037842901300244X-1801': [(571, 475, 47677, 176), (1694, 15390)],\n",
       " 'S0921818113002245-1571': [(13753,), (119,), (5646, 241), (5471,)],\n",
       " 'S0921818113002245-1752': [(119,), (5471,)],\n",
       " 'S0921818113002245-859': [(119,)],\n",
       " 'S0921818113002245-882': [(119,), (10806, 3677)],\n",
       " 'S0925443913001385-1319': [(16258, 23073, 1054),\n",
       "  (4892, 859, 1344),\n",
       "  (207,),\n",
       "  (11828, 19245)],\n",
       " 'S0925443913001385-1429': [(119, 448),\n",
       "  (47049, 571, 73, 18517),\n",
       "  (791, 73, 18517)],\n",
       " 'S0925443913001385-1526': [(207, 36, 605, 73, 705, 43), (47049, 571)],\n",
       " 'S0925443913001385-1621': [(207,)],\n",
       " 'S0925443913001385-1638': [(207,)],\n",
       " 'S0925443913001385-1646': [(207,)],\n",
       " 'S0925443913001385-1683': [(207,)],\n",
       " 'S0925443913001385-839': [(47049, 571)],\n",
       " 'S0925443913001385-849': [(47049, 571)],\n",
       " 'S0925443913003037-1397': [(207,)],\n",
       " 'S0925443913003037-654': [(12857,)],\n",
       " 'S0927024813001955-1005': [(12938, 347), (207,)],\n",
       " 'S0927024813001955-576': [(298,), (3583,), (28235,)],\n",
       " 'S0927024813001955-679': [(7033,), (28235,), (207,), (13753, 176, 73, 13436)],\n",
       " 'S0927024813001955-812': [(298,), (12938, 347), (43773,), (22984, 73, 43619)],\n",
       " 'S0927024813002420-1032': [(47602, 73, 13753, 176),\n",
       "  (13728, 207),\n",
       "  (846,),\n",
       "  (28235,)],\n",
       " 'S0927024813002420-1202': [],\n",
       " 'S0927024813002420-975': [(242, 846),\n",
       "  (12938, 347),\n",
       "  (207,),\n",
       "  (571, 13200, 47677, 134),\n",
       "  (30562, 338),\n",
       "  (5806, 11032, 2833),\n",
       "  (3849, 5782, 73, 29)],\n",
       " 'S0927024813002961-1051': [(207,)],\n",
       " 'S0927024813002961-1085': [(12938, 347), (771, 73, 119, 176)],\n",
       " 'S0927024813002961-1322': [(207,)],\n",
       " 'S0927024813002961-1334': [(12938, 347), (771, 73, 119, 176), (207,)],\n",
       " 'S0927024813002961-1357': [(207, 73, 102)],\n",
       " 'S0927024813003036-1981': [(29,), (12938, 347), (207,)],\n",
       " 'S0927024813003036-2011': [(298,),\n",
       "  (4691,),\n",
       "  (12938, 347),\n",
       "  (642, 288),\n",
       "  (13753, 47677, 246),\n",
       "  (4339,)],\n",
       " 'S0927775713009606-1074': [(28235,),\n",
       "  (13753, 246, 821, 47677, 134),\n",
       "  (605, 73, 605),\n",
       "  (119, 176, 821, 47677, 134)],\n",
       " 'S0927775713009606-1216': [(12938,), (29,)],\n",
       " 'S0927775713009606-1361': [(28235,)],\n",
       " 'S0950705113001895-23682': [(207,)],\n",
       " 'S0950705113001895-23699': [(207,)],\n",
       " 'S095741741101342X-2624': [(207,)],\n",
       " 'S095741741101342X-726': [(207,)],\n",
       " 'S0960148113002048-3775': [(37825,)],\n",
       " 'S0960148113002735-1289': [(119,), (330, 771)],\n",
       " 'S0960148113002735-1989': [(29,), (207,)],\n",
       " 'S0960148113002735-2182': [(29,)],\n",
       " 'S0960148113004989-2841': [(6,),\n",
       "  (119, 176, 579, 47677, 134),\n",
       "  (119,),\n",
       "  (29,),\n",
       "  (119, 579, 47677, 176)],\n",
       " 'S0960148113004989-3203': [(4691,), (119,), (29,)],\n",
       " 'S0960148113004989-3258': [(119,), (19454,), (207,)],\n",
       " 'S0960148113004989-3277': [(298,), (29,)],\n",
       " 'S0960148113004989-3327': [(19454,), (207,)],\n",
       " 'S0960148113005727-1181': [(207,)],\n",
       " 'S0960148113005727-1203': [(207,)],\n",
       " 'S0960148113005727-1451': [(207,)],\n",
       " 'S0960148113005727-1466': [(1741, 256, 14447),\n",
       "  (19454,),\n",
       "  (207,),\n",
       "  (21996,),\n",
       "  (565, 14447),\n",
       "  (12857,)],\n",
       " 'S0960148113005727-1494': [(13566, 1580, 332, 228, 76), (207,)],\n",
       " 'S0960148113005727-739': [],\n",
       " 'S0960148113005727-855': [(180,), (207,)],\n",
       " 'S0960148113005727-904': [(207, 228, 76)],\n",
       " 'S0960896612001022-1223': [(571, 73, 574), (12857,)],\n",
       " 'S0967064513002774-1376': [(298,),\n",
       "  (4691,),\n",
       "  (12938, 347),\n",
       "  (207,),\n",
       "  (43619,),\n",
       "  (7033,)],\n",
       " 'S1161030113001950-923': [(12857,), (207,)],\n",
       " 'S1359645413009816-1712': [(530, 5251, 12, 134)],\n",
       " 'S1359645413009816-2227': [(5471,)],\n",
       " 'S1359645413009816-2243': [(530, 73, 4691), (28235,), (330, 846)],\n",
       " 'S1359645413009816-2973': [(119,), (530,)],\n",
       " 'S1359835X13001875-1359': [(119,), (18909, 34125, 16710), (119, 47677, 176)],\n",
       " 'S1367912013002277-1213': [(47049, 119)],\n",
       " 'S1387700313001822-661': [(26296, 3733), (28235,)],\n",
       " 'S1388248113001951-339': [(47602, 821, 47677, 112),\n",
       "  (846,),\n",
       "  (22984, 25434, 47677, 132)],\n",
       " 'S1389128612002496-5994': [(207,)],\n",
       " 'S1389128612002496-6119': [(4339,)],\n",
       " 'S1389128612002496-6138': [(36030,)],\n",
       " 'S1550413113004920-1509': [(34606,)],\n",
       " 'S175058361300203X-1240': [(7629, 102), (12938, 347), (9043, 73, 119, 246)],\n",
       " 'S175058361300203X-1280': [(37825,)],\n",
       " 'S175058361300203X-1483': [(119,), (207,)],\n",
       " 'S175058361300203X-1542': [(119, 73, 29), (12938, 347), (207,)],\n",
       " 'S175058361300203X-1556': [(12938, 347), (207,)],\n",
       " 'S175058361300203X-1638': [(12938, 347)],\n",
       " 'S1750583613004192-1126': [(448, 90, 73, 4503),\n",
       "  (31507, 14352, 7926),\n",
       "  (7203,),\n",
       "  (12857,)],\n",
       " 'S1750583613004192-1267': [(207,), (13566,)],\n",
       " 'S1750583613004192-1689': [(7629, 102), (5646, 268), (12857,)],\n",
       " 'S1750583613004192-714': [(119, 4311, 462), (119,), (12857,), (448, 90)],\n",
       " 'S1873506113001116-1204': [(298,),\n",
       "  (207,),\n",
       "  (10212, 3443),\n",
       "  (12851,),\n",
       "  (12851, 228, 9078),\n",
       "  (1208,)],\n",
       " 'S1873506113001116-1369': [(7033,), (10212, 3443), (207,)],\n",
       " 'S1873506113001116-1456': [(207,), (18517,)],\n",
       " 'S1873506113001116-710': [(298,), (47049, 119), (10212, 3443)],\n",
       " 'S1873506113001116-978': [(10212, 3443)],\n",
       " 'S1873506114000075-1104': [(207,)],\n",
       " 'S1873506114000075-1132': [(298,)],\n",
       " 'S1873506114000075-1242': [(47049, 571, 73, 18517), (207,)],\n",
       " 'S1873506114000075-665': [(47049, 119), (5471,)],\n",
       " 'S2211124712002884-1060': [(791, 73, 18517), (207,)],\n",
       " 'S2211124712002884-1110': [(1694, 15390),\n",
       "  (47049, 571, 73, 119),\n",
       "  (22984, 73, 18517),\n",
       "  (7033,),\n",
       "  (1208,)],\n",
       " 'S2211124712002884-620': [(47049, 119)],\n",
       " 'S2211124712002884-649': [(207,)],\n",
       " 'S2211124712002884-682': [(47049, 119)],\n",
       " 'S2211124712002884-705': [(207,), (5039,)],\n",
       " 'S2211124712002884-903': [(180,)],\n",
       " 'S2211124713006475-1195': [(7033,)],\n",
       " 'S2211124713006475-1205': [(1694, 15390)],\n",
       " 'S2211124713006475-741': [(47049, 119)],\n",
       " 'S2211124713006475-841': [(1694, 15390)],\n",
       " 'S2213158213000302-1597': [(4339,)],\n",
       " 'S2213158213000582-1041': [(4339,)],\n",
       " 'S2213158213000582-1050': [(4339,)],\n",
       " 'S2213158213000582-1183': [(29,), (4339,)],\n",
       " 'S2213158213000582-1279': [(29,), (4339,), (45189,), (4691, 11282)],\n",
       " 'S2213158213000582-1309': [(4339,)],\n",
       " 'S2213158213000582-1327': [(5471, 228, 526)],\n",
       " 'S2213158213000582-1340': [(37825,), (4339,), (207,)],\n",
       " 'S2213158213000582-1390': [(4339,)],\n",
       " 'S2213158213000582-1398': [(4339,)],\n",
       " 'S2213158213000582-1410': [(4339,)],\n",
       " 'S2213158213000582-1424': [(4339,)],\n",
       " 'S2213158213000582-1469': [(4339,)],\n",
       " 'S2213158213000582-751': [(4339,)],\n",
       " 'S2213158213000582-766': [(4339,)],\n",
       " 'S2213158213001253-2433': [(207,)],\n",
       " 'S2213158213001253-2583': [(5471,)],\n",
       " 'S2213671113000738-430': [(34606,)],\n",
       " 'S2213671113000738-435': [(47049, 119)],\n",
       " 'S2213671113000738-445': [(5039,)],\n",
       " 'S2213671113000738-447': [(207,)],\n",
       " 'S2213671113000738-485': [(34606,)],\n",
       " 'S2213671113000738-647': [(1694, 15390)],\n",
       " 'S2213671113000738-667': [(2590, 73, 18517), (5039,)],\n",
       " 'S2213671113000738-684': [(34606,), (207,)],\n",
       " 'S2213671113000738-738': [(34606,)],\n",
       " 'S2213671113000738-787': [(47049, 119)],\n",
       " 'S2213671113000908-640': [(7033,)],\n",
       " 'S2213671113000908-643': [(7033,)],\n",
       " 'S2213671113000908-810': [(207,)],\n",
       " 'S2213671113000908-979': [(5039,)],\n",
       " 'S2213671113000921-1279': [(207,)],\n",
       " 'S2213671113000921-714': [(47049, 119)],\n",
       " 'S2213671113000921-756': [(47049, 119)],\n",
       " 'S2213671113000921-994': [(10212, 3443), (3998, 6909), (207,)],\n",
       " 'S2213671113001306-1286': [(1694, 15390)],\n",
       " 'S2213671113001306-1385': [(3583,)],\n",
       " 'S2213671113001306-1398': [(22984,)],\n",
       " 'S2213671113001306-1404': [(207,), (2151,), (1694, 15390)],\n",
       " 'S2213671113001306-1520': [(28904, 13448), (47049, 119), (5471,)],\n",
       " 'S2213671113001306-885': [(47049, 119)],\n",
       " 'S2213671113001306-907': [(47049, 119)],\n",
       " 'S2213671113001306-908': [(47049, 119)],\n",
       " 'S2213671113001306-910': [(47049, 119), (6230,)]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_encodings_per_docId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docId</th>\n",
       "      <th>annotId</th>\n",
       "      <th>annotType</th>\n",
       "      <th>annotSpan</th>\n",
       "      <th>subSpanType</th>\n",
       "      <th>linkId</th>\n",
       "      <th>linkSpan</th>\n",
       "      <th>subSpan</th>\n",
       "      <th>unit</th>\n",
       "      <th>unitEncoded</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comboId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [docId, annotId, annotType, annotSpan, subSpanType, linkId, linkSpan, subSpan, unit, unitEncoded, misc]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combo_annot_processed.loc[combo_annot_processed['docId']=='S0006322312001096-1190']\n",
    "combo_annot_processed.loc[combo_annot_processed['docId']=='S0022000014000026-7850']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1746/2806701866.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teest_ds['new_labels'] = teest_ds.apply(lambda row: generate_new_labels(row['labels'],row['input_ids'],row['doc_or_sent_id']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "def generate_new_labels(lbls, txt_encoding, docId):\n",
    "    lbls = lbls\n",
    "    txt_encoding = txt_encoding\n",
    "    docId = docId\n",
    "    lbls_ones = [0 if i>1 else i for i in lbls]\n",
    "    quantity_encodings = np.multiply(txt_encoding,lbls_ones)\n",
    "\n",
    "    embeddings_list = unit_encodings_per_docId[docId] # list of all unit embeddings per doc\n",
    "    for one_embedding in embeddings_list:\n",
    "        embeddings = np.asarray(one_embedding)\n",
    "        len_embedding = len(embeddings)\n",
    "        indices = np.where(quantity_encodings == embeddings[0])[0] # get array of indices matching first number\n",
    "\n",
    "    #check if the embedding matches\n",
    "        for i in indices:\n",
    "            if quantity_encodings[i:i+a].all() == embeddings.all():\n",
    "                quantity_encodings[i:i+a] = np.full((1, a), 400000000)\n",
    "            else:\n",
    "                continue\n",
    "    replace_label = np.where(quantity_encodings == 400000000, 4, 0)\n",
    "    new_labels = np.add(replace_label, lbls)\n",
    "    output = new_labels\n",
    "    \n",
    "\n",
    "    # for i in unit_encodings_per_docId[docId]:\n",
    "    #     if len(i) == 1:\n",
    "    #         # marks unit encoding with a 4, otherwise 0\n",
    "    #         replace_label = np.where(quantity_encodings == i[0], 4, 0)\n",
    "    #         # add vector to original labels so that units are now marked as 5\n",
    "    #         new_labels = np.add(replace_label, lbls)\n",
    "    #         output = new_labels\n",
    "    #     elif len(i) == 0:\n",
    "    #         continue\n",
    "    #     else:\n",
    "    #         for j in i:\n",
    "    #             pass\n",
    "    #             # can i replace each of them separately idk\n",
    "                \n",
    "    return output\n",
    "\n",
    "\n",
    "teest_ds['new_labels'] = teest_ds.apply(lambda row: generate_new_labels(row['labels'],row['input_ids'],row['doc_or_sent_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>doc_or_sent_id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>new_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103512004009-4492</td>\n",
       "      <td>[0, 2709, 41, 16, 35941, 5466, 19, 10, 5181, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103512002801-1342</td>\n",
       "      <td>[0, 500, 26343, 16, 25012, 17, 27, 29, 1154, 2...</td>\n",
       "      <td>[0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, ...</td>\n",
       "      <td>[0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0016236113008041-3171</td>\n",
       "      <td>[0, 44105, 4, 231, 924, 5, 26069, 9, 3694, 478...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0378383912000130-1096</td>\n",
       "      <td>[0, 14699, 12, 22760, 9, 1421, 12, 37466, 1979...</td>\n",
       "      <td>[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0016236113008041-2924</td>\n",
       "      <td>[0, 104, 40275, 1966, 2584, 66, 15, 14077, 482...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0925443913001385-1429</td>\n",
       "      <td>[0, 33837, 3024, 19961, 1001, 3662, 13651, 58,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0167278913001450-12425</td>\n",
       "      <td>[0, 44105, 4, 132, 924, 10, 5204, 15694, 15566...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 2, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 2, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0012821X12004384-1148</td>\n",
       "      <td>[0, 45311, 1022, 3059, 19, 5, 37527, 42416, 23...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0006322312001096-626</td>\n",
       "      <td>[0, 26039, 41156, 10414, 27335, 20117, 12366, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 1, 1, 2, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 1, 1, 2, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0016236113008041-3112</td>\n",
       "      <td>[0, 133, 45033, 20424, 5448, 21, 15050, 11, 10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103512004009-3976</td>\n",
       "      <td>[0, 133, 1683, 9, 2992, 5, 11545, 5838, 15, 5,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103513005058-1737</td>\n",
       "      <td>[0, 9157, 6342, 27748, 9, 41871, 11, 6507, 661...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0301010413004096-693</td>\n",
       "      <td>[0, 44791, 2383, 34098, 7208, 36, 8756, 597, 4...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0006322312001096-1275</td>\n",
       "      <td>[0, 15243, 10, 239, 1263, 7, 5, 2658, 36, 9435...</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 1, 5, 5, 5, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0378383912000130-3827</td>\n",
       "      <td>[0, 1121, 5709, 7, 5, 112, 4, 245, 15408, 4105...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>S0019103512003995-2681</td>\n",
       "      <td>[0, 133, 40002, 672, 9, 5, 40150, 1421, 16, 55...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       attention_mask  \\\n",
       "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "5   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "7   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "11  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "13  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "14  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "15  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "16  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "17  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "18  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "19  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "             doc_or_sent_id  \\\n",
       "4    S0019103512004009-4492   \n",
       "5    S0019103512002801-1342   \n",
       "6    S0016236113008041-3171   \n",
       "7    S0378383912000130-1096   \n",
       "8    S0016236113008041-2924   \n",
       "9    S0925443913001385-1429   \n",
       "10  S0167278913001450-12425   \n",
       "11   S0012821X12004384-1148   \n",
       "12    S0006322312001096-626   \n",
       "13   S0016236113008041-3112   \n",
       "14   S0019103512004009-3976   \n",
       "15   S0019103513005058-1737   \n",
       "16    S0301010413004096-693   \n",
       "17   S0006322312001096-1275   \n",
       "18   S0378383912000130-3827   \n",
       "19   S0019103512003995-2681   \n",
       "\n",
       "                                            input_ids  \\\n",
       "4   [0, 2709, 41, 16, 35941, 5466, 19, 10, 5181, 2...   \n",
       "5   [0, 500, 26343, 16, 25012, 17, 27, 29, 1154, 2...   \n",
       "6   [0, 44105, 4, 231, 924, 5, 26069, 9, 3694, 478...   \n",
       "7   [0, 14699, 12, 22760, 9, 1421, 12, 37466, 1979...   \n",
       "8   [0, 104, 40275, 1966, 2584, 66, 15, 14077, 482...   \n",
       "9   [0, 33837, 3024, 19961, 1001, 3662, 13651, 58,...   \n",
       "10  [0, 44105, 4, 132, 924, 10, 5204, 15694, 15566...   \n",
       "11  [0, 45311, 1022, 3059, 19, 5, 37527, 42416, 23...   \n",
       "12  [0, 26039, 41156, 10414, 27335, 20117, 12366, ...   \n",
       "13  [0, 133, 45033, 20424, 5448, 21, 15050, 11, 10...   \n",
       "14  [0, 133, 1683, 9, 2992, 5, 11545, 5838, 15, 5,...   \n",
       "15  [0, 9157, 6342, 27748, 9, 41871, 11, 6507, 661...   \n",
       "16  [0, 44791, 2383, 34098, 7208, 36, 8756, 597, 4...   \n",
       "17  [0, 15243, 10, 239, 1263, 7, 5, 2658, 36, 9435...   \n",
       "18  [0, 1121, 5709, 7, 5, 112, 4, 245, 15408, 4105...   \n",
       "19  [0, 133, 40002, 672, 9, 5, 40150, 1421, 16, 55...   \n",
       "\n",
       "                                               labels  \\\n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5   [0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, ...   \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, ...   \n",
       "7   [0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, ...   \n",
       "10  [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 2, 1, 1, ...   \n",
       "11  [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "12  [0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 1, 1, 2, 0, 0, ...   \n",
       "13  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "14  [0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "15  [0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, ...   \n",
       "16  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "17  [0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "18  [0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, ...   \n",
       "19  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           new_labels  \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5   [0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, ...  \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, ...  \n",
       "7   [0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...  \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, ...  \n",
       "10  [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 2, 1, 1, ...  \n",
       "11  [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "12  [0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 1, 1, 2, 0, 0, ...  \n",
       "13  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "14  [0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "15  [0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, ...  \n",
       "16  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "17  [0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 1, 5, 5, 5, 1, ...  \n",
       "18  [0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 0, 0, 0, 1, 1, ...  \n",
       "19  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teest_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'S0022000014000026-7850'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/michelle/MeasEval/baselines/batch_doc_pipeline_cs_WIP.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcasper.sams-data.dev/home/michelle/MeasEval/baselines/batch_doc_pipeline_cs_WIP.ipynb#ch0000072vscode-remote?line=0'>1</a>\u001b[0m unit_encodings_per_docId[\u001b[39m'\u001b[39;49m\u001b[39mS0022000014000026-7850\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'S0022000014000026-7850'"
     ]
    }
   ],
   "source": [
    "unit_encodings_per_docId['S0022000014000026-7850']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_distribution(dataset):\n",
    "    \"\"\"\n",
    "    Function to visualize label distribution\n",
    "\n",
    "    Input: train/test/dev dataframe with column 'labels'\n",
    "    Output: prints graph of proportion of labels and returns dict\n",
    "    with label as key and proportion as value\n",
    "    \"\"\"\n",
    "\n",
    "    # turn label array into counts array\n",
    "    def indiv_label_distribution(array_labels):\n",
    "        array_labels = array_labels\n",
    "        (unique, counts) = np.unique(array_labels, return_counts=True)\n",
    "        freq = np.asarray((unique, counts)).T\n",
    "        return freq\n",
    "\n",
    "    dataset = dataset\n",
    "    label_column = dataset['labels']\n",
    "    distr_dict = {}\n",
    "    dataset['distr_arr'] = label_column.apply(indiv_label_distribution)\n",
    "\n",
    "    # add counts from counts array into dictionary\n",
    "    def add_counts(array_counts):\n",
    "        array_counts = array_counts   \n",
    "        for row in array_counts:\n",
    "            if row[0] in distr_dict.keys():\n",
    "                distr_dict[row[0]] += row[1]\n",
    "            else:\n",
    "                distr_dict[row[0]] = row[1]\n",
    "\n",
    "    dataset['distr_arr'].apply(add_counts)\n",
    "\n",
    "    # remove 0 label and its counts\n",
    "    del distr_dict[0]\n",
    "\n",
    "    # plot\n",
    "    distr_dict_pct = {k: v / total for total in (sum(distr_dict.values()),) for k, v in distr_dict.items()}\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    lists = sorted(distr_dict_pct.items())\n",
    "    x, y = zip(*lists)\n",
    "    plt.bar(x, y)\n",
    "    plt.title(\"label distribution\")\n",
    "    plt.xlabel(\"label\")\n",
    "    plt.ylabel(\"proportion of all labels\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"label counts:\\n\", distr_dict, \"\\n\")\n",
    "    print(\"label proportions:\")\n",
    "    return distr_dict_pct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label counts:\n",
      " {1: 4467, 2: 1707, 3: 3227, 4: 1286} \n",
      "\n",
      "label proportions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.4179844671095724,\n",
       " 2: 0.15972677084308037,\n",
       " 3: 0.3019556470478151,\n",
       " 4: 0.12033311499953214}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distribution(stage1_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label counts:\n",
      " {1: 1185, 2: 530, 3: 745, 4: 315} \n",
      "\n",
      "label proportions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.42702702702702705,\n",
       " 2: 0.19099099099099098,\n",
       " 3: 0.26846846846846845,\n",
       " 4: 0.11351351351351352}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distribution(stage1_dev_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label counts:\n",
      " {1: 344, 2: 223, 3: 465, 4: 131} \n",
      "\n",
      "label proportions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.29578675838349094,\n",
       " 2: 0.19174548581255374,\n",
       " 3: 0.3998280309544282,\n",
       " 4: 0.11263972484952708}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distribution(stage1_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage1_n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Matt\n",
    "# def shorten_txt_encoding(txt, shorten_by : int):       \n",
    "#     pass...\n",
    "\n",
    "# generate a list of docIds that have token collision after shortening\n",
    "\n",
    "# toks = list(stage1_dev_ds.sample(1)['input_ids'])\n",
    "\n",
    "# print(toks[0])\n",
    "\n",
    "# tokenizer.decode(toks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(tokenized_dataset, batch_size, device):\n",
    "    num_examples = int(tokenized_dataset.shape[0] / batch_size)\n",
    "    batch_sizes = [batch_size for x in range(num_examples)]\n",
    "    last_batch_size = tokenized_dataset.shape[0] % batch_size\n",
    "    if last_batch_size:\n",
    "        batch_sizes.append(last_batch_size)\n",
    "    # print(batch_sizes)\n",
    "\n",
    "    batched_dataset = []\n",
    "\n",
    "    idf_to_torch = lambda df : torch.tensor(np.array([list(map(int,r)) for r in df])).to(device)\n",
    "\n",
    "    for idx, size in enumerate(batch_sizes):\n",
    "        start = sum(batch_sizes[:idx])\n",
    "        end = sum(batch_sizes[:idx]) + size - 1\n",
    "        # print(start,end,idx)\n",
    "        input_ids = idf_to_torch(tokenized_dataset['input_ids'].loc[start:end])\n",
    "        attention_mask = idf_to_torch(tokenized_dataset['attention_mask'].loc[start:end])\n",
    "        labels = idf_to_torch(tokenized_dataset['labels'].loc[start:end])\n",
    "        doc_or_sent_id = list(tokenized_dataset['doc_or_sent_id'].loc[start:end])\n",
    "        \n",
    "        batch = {\n",
    "            'input_ids':input_ids,\n",
    "            'labels':labels,\n",
    "            'attention_mask':attention_mask,\n",
    "            'doc_or_sent_id':doc_or_sent_id\n",
    "\n",
    "        }\n",
    "        \n",
    "        batched_dataset.append(batch)\n",
    "\n",
    "    return batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# batchify ####################\n",
    "\n",
    "batched_train_ds = batchify(stage1_train_ds[['attention_mask','input_ids','labels','doc_or_sent_id']], batch_size, device)\n",
    "batched_dev_ds = batchify(stage1_dev_ds[['attention_mask','input_ids','labels','doc_or_sent_id']], batch_size, device)\n",
    "batched_test_ds = batchify(stage1_test_ds[['attention_mask','input_ids','labels','doc_or_sent_id']], batch_size, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 44105,     4,  ...,     1,     1,     1],\n",
       "         [    0,   970,    32,  ...,     1,     1,     1],\n",
       "         [    0,   170,   220,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    0, 14699,    12,  ...,     1,     1,     1],\n",
       "         [    0,   104, 40275,  ...,     1,     1,     1],\n",
       "         [    0, 33837,  3024,  ...,     1,     1,     1]], device='cuda:0'),\n",
       " 'labels': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 3, 3,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
       " 'doc_or_sent_id': ['S0016236113008041-3290',\n",
       "  'S0006322312001096-1271',\n",
       "  'S0022000014000026-7850',\n",
       "  'S0019103513005058-4158',\n",
       "  'S0019103512004009-4492',\n",
       "  'S0019103512002801-1342',\n",
       "  'S0016236113008041-3171',\n",
       "  'S0378383912000130-1096',\n",
       "  'S0016236113008041-2924',\n",
       "  'S0925443913001385-1429']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Quantity': 1, 'MeasuredProperty': 2, 'MeasuredEntity': 3, 'Qualifier': 4}\n"
     ]
    }
   ],
   "source": [
    "demo_batch = 2\n",
    "\n",
    "demo_batch = batched_train_ds[demo_batch]\n",
    "\n",
    "\n",
    "demo_doc = demo_batch['doc_or_sent_id'][0]\n",
    "demo_ids = demo_batch['input_ids'].cpu().numpy()[0]\n",
    "demo_tokens = tokenizer.decode(demo_batch['input_ids'].cpu().numpy()[0])\n",
    "demo_labels = demo_batch['labels'].cpu().numpy()[0]\n",
    "demo_mask = demo_batch['attention_mask'].cpu().numpy()[0]\n",
    "latch_print = False\n",
    "labeled_tokens = ''\n",
    "for id, lab in zip(demo_ids, demo_labels):\n",
    "    if lab:\n",
    "        labeled_tokens = labeled_tokens + tokenizer.decode(id) + ' '\n",
    "\n",
    "print(task_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S0925443913001385-1646'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0  1121   645     7  3094   549     5 18838  7205  1092 31425    67\n",
      " 26914  1022    11 15229     8  6559     9     5 43261 14966   366 38868\n",
      "   739     8   650  2849 46210     6 43261   784  2459  1626    31 43318\n",
      " 19961  1001  3662 13651    36 40747     8   797    43    58 13484  1070\n",
      "    15    16 36557 15557 43164 14170 12003 20676    36   698  2383   541\n",
      "  4234    25    11  8526     4   646  3706 48610   318  6559     9  1169\n",
      "     5   739  2849 19304    50     5  1445 14966   366  4399    21  2132\n",
      "   172     5  3854     9  1736 14966   366 38868 17792    74   464   624\n",
      "     5 43141  4392     4   374  1966 18838  7205  1092    31     5  3186\n",
      "    21 12246  8065    11    70 44807    53 44012    11     5 44807  4292\n",
      "    19 41601    12 10463   791   131   959    24    21 28840 11640    31\n",
      "     5   481  3716    36   506 29866   112     8   132     6 20001     4\n",
      "   195   322   152    21    11  5709     7     5   797    14 22495    10\n",
      "  3716     9   481 18838  7205  1092     6    61    34    57   431     7\n",
      " 10754    19 22808   500 11674   646  4419  8174 18838  7205   246    21\n",
      "    67  2829  2906    11  2087  4590    53  2442    11 44807  4292    19\n",
      "     5   739  2849 19304     4    20 18838  7205  1092 31425  7284    55\n",
      "  6473   352    15     5   650 14966   366 38868  2849 19304     6    19\n",
      "   211   591   246  4100 32512     8 18838  3888  1366   387   303    11\n",
      "   795  5353   129    11 44807   204     8   195    53  3680    19  1122\n",
      "  5204   194  1389     8  3854  4392  1118     7   797     4  1773 22808\n",
      "   500 11674     8 18838  7205  1092    33    57  1027    25 10754   994\n",
      "     6    52 13773   258     5  5204   194   672     8 43141  3854     9\n",
      " 22808   500 11674     7   192   114   209    58  2132    30     5 18838\n",
      "  7205  1092 31425     4  7806  1389    11     5  2087  7728    58  8065\n",
      "     7  5549   207     9   797   923    36 44105     4   195   387    43\n",
      "    53  3854    11     5 43141  1382  2743 32512    19     5  8219     9\n",
      " 13484   365     6   147  1389    58   795    87   797    36 44105     4\n",
      "   195   250  2576  9217   322     2     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n"
     ]
    }
   ],
   "source": [
    "print(demo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 0 4 4 1 1 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(demo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>In order to determine whether the MRPL12 mutation also induced changes in composition and assembly of the mitochondrial ribosomal large and small subunits, mitochondrial lysates from cultured fibroblasts (subject and control) were fractionated on isokinetic sucrose gradients (10â€“30%, as in Ref. [47]). If assembly of either the large subunit or the entire ribosome was affected then the distribution of individual ribosomal proteins would change within the gradient profile. On analysis MRPL12 from the patient was substantially decreased in all fractions but detectable in the fractions consistent with mt-LSU; however it was noticeably absent from the free pool (fractions 1 and 2, Fig. 5). This was in contrast to the control that exhibited a pool of free MRPL12, which has been reported to interact with POLRMT [56]. MRPL3 was also slightly reduced in subject cells but remained in fractions consistent with the large subunit. The MRPL12 mutation impacted more modestly on the small ribosomal subunit, with DAP3 apparently unaffected and MRPS18B found in lower amounts only in fractions 4 and 5 but otherwise with similar steady state levels and distribution profile compared to control. Since POLRMT and MRPL12 have been published as interactors, we analyzed both the steady state level and gradient distribution of POLRMT to see if these were affected by the MRPL12 mutation. Overall levels in the subject sample were decreased to 63% of control value (Fig. 5B) but distribution in the gradient appeared largely unaffected with the exception of fraction 11, where levels were lower than control (Fig. 5A bottom panels).</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "print(demo_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docId</th>\n",
       "      <th>annotId</th>\n",
       "      <th>annotType</th>\n",
       "      <th>annotSpan</th>\n",
       "      <th>subSpanType</th>\n",
       "      <th>linkId</th>\n",
       "      <th>linkSpan</th>\n",
       "      <th>subSpan</th>\n",
       "      <th>unit</th>\n",
       "      <th>unitEncoded</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comboId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0925443913001385-1646_T1-1</th>\n",
       "      <td>S0925443913001385-1646</td>\n",
       "      <td>T1-1</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[277, 283]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>[207]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0925443913001385-1646_T2-1</th>\n",
       "      <td>S0925443913001385-1646</td>\n",
       "      <td>T2-1</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[247, 275]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T1-1</td>\n",
       "      <td>[277, 283]</td>\n",
       "      <td>[247, 283]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0925443913001385-1646_T1-2</th>\n",
       "      <td>S0925443913001385-1646</td>\n",
       "      <td>T1-2</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[1438, 1441]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>[207]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0925443913001385-1646_T2-2</th>\n",
       "      <td>S0925443913001385-1646</td>\n",
       "      <td>T2-2</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[1391, 1419]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T1-2</td>\n",
       "      <td>[1438, 1441]</td>\n",
       "      <td>[1391, 1441]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0925443913001385-1646_T4-2</th>\n",
       "      <td>S0925443913001385-1646</td>\n",
       "      <td>T4-2</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[1445, 1458]</td>\n",
       "      <td>HasProperty</td>\n",
       "      <td>T2-2</td>\n",
       "      <td>[1391, 1419]</td>\n",
       "      <td>[1391, 1458]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0925443913001385-1646_T3-2</th>\n",
       "      <td>S0925443913001385-1646</td>\n",
       "      <td>T3-2</td>\n",
       "      <td>Qualifier</td>\n",
       "      <td>[1425, 1437]</td>\n",
       "      <td>Qualifies</td>\n",
       "      <td>T2-2</td>\n",
       "      <td>[1391, 1419]</td>\n",
       "      <td>[1391, 1437]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              docId annotId         annotType  \\\n",
       "comboId                                                                         \n",
       "S0925443913001385-1646_T1-1  S0925443913001385-1646    T1-1          Quantity   \n",
       "S0925443913001385-1646_T2-1  S0925443913001385-1646    T2-1    MeasuredEntity   \n",
       "S0925443913001385-1646_T1-2  S0925443913001385-1646    T1-2          Quantity   \n",
       "S0925443913001385-1646_T2-2  S0925443913001385-1646    T2-2  MeasuredProperty   \n",
       "S0925443913001385-1646_T4-2  S0925443913001385-1646    T4-2    MeasuredEntity   \n",
       "S0925443913001385-1646_T3-2  S0925443913001385-1646    T3-2         Qualifier   \n",
       "\n",
       "                                annotSpan  subSpanType linkId      linkSpan  \\\n",
       "comboId                                                                       \n",
       "S0925443913001385-1646_T1-1    [277, 283]          NaN    NaN           NaN   \n",
       "S0925443913001385-1646_T2-1    [247, 275]  HasQuantity   T1-1    [277, 283]   \n",
       "S0925443913001385-1646_T1-2  [1438, 1441]          NaN    NaN           NaN   \n",
       "S0925443913001385-1646_T2-2  [1391, 1419]  HasQuantity   T1-2  [1438, 1441]   \n",
       "S0925443913001385-1646_T4-2  [1445, 1458]  HasProperty   T2-2  [1391, 1419]   \n",
       "S0925443913001385-1646_T3-2  [1425, 1437]    Qualifies   T2-2  [1391, 1419]   \n",
       "\n",
       "                                  subSpan unit unitEncoded misc  \n",
       "comboId                                                          \n",
       "S0925443913001385-1646_T1-1           NaN    %       [207]  NaN  \n",
       "S0925443913001385-1646_T2-1    [247, 283]  NaN         NaN  NaN  \n",
       "S0925443913001385-1646_T1-2           NaN    %       [207]  NaN  \n",
       "S0925443913001385-1646_T2-2  [1391, 1441]  NaN         NaN  NaN  \n",
       "S0925443913001385-1646_T4-2  [1391, 1458]  NaN         NaN  NaN  \n",
       "S0925443913001385-1646_T3-2  [1391, 1437]  NaN         NaN  NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_annot_processed.loc[combo_annot['docId']==demo_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is okin etic  suc rose  grad ients 10 â€“ 30 %,  levels  in  the  subject  sample  decreased  to  63 %  control  value \n"
     ]
    }
   ],
   "source": [
    "print(labeled_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': 0, '</s>': 2, '<unk>': 3, '<pad>': 1, '<mask>': 50264}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_token_map = dict(zip(tokenizer.all_special_tokens,tokenizer.all_special_ids))\n",
    "special_token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0925443913001385-1646_T2-1\n",
      "MeasuredEntity\n",
      "HasQuantity\n",
      "247 283\n",
      "[16, 36557, 15557, 43164, 14170, 12003, 20676, 36, 698, 2383, 541, 4234]\n",
      "[3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1]\n",
      " isokinetic sucrose gradients (10â€“30%,\n",
      "\n",
      "S0925443913001385-1646_T2-2\n",
      "MeasuredProperty\n",
      "HasQuantity\n",
      "1391 1441\n",
      "[1389, 11, 5, 2087, 7728, 58, 8065, 7, 5549, 207]\n",
      "[2, 2, 2, 2, 2, 0, 4, 4, 1, 1]\n",
      " levels in the subject sample were decreased to 63%\n",
      "\n",
      "S0925443913001385-1646_T4-2\n",
      "MeasuredEntity\n",
      "HasProperty\n",
      "1391 1458\n",
      "[1389, 11, 5, 2087, 7728, 58, 8065, 7, 5549, 207, 9, 797, 923]\n",
      "[2, 2, 2, 2, 2, 0, 4, 4, 1, 1, 0, 3, 3]\n",
      " levels in the subject sample were decreased to 63% of control value\n",
      "\n",
      "S0925443913001385-1646_T3-2\n",
      "Qualifier\n",
      "Qualifies\n",
      "1391 1437\n",
      "[1389, 11, 5, 2087, 7728, 58, 8065, 7]\n",
      "[2, 2, 2, 2, 2, 0, 4, 4]\n",
      " levels in the subject sample were decreased to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_annots = combo_annot_processed.loc[combo_annot['docId']==demo_doc]\n",
    "\n",
    "demo_txt = combo_txt[demo_doc]\n",
    "\n",
    "encoded_demo_txt = tokenizer(demo_txt, padding='max_length', max_length=512, truncation=True)\n",
    "demo_token_startchar = []\n",
    "for idx, id in enumerate(encoded_demo_txt['input_ids']):\n",
    "    try: tokenCharStart = encoded_demo_txt.token_to_chars(idx).start\n",
    "    except: tokenCharStart = np.nan\n",
    "    demo_token_startchar.append(tokenCharStart)\n",
    "\n",
    "subSpan_ds = {}\n",
    "for comboId, annot in demo_annots.iterrows():\n",
    "    if isinstance(annot['subSpanType'],float): continue # nans are floats\n",
    "    print(comboId)\n",
    "    print(annot['annotType'])\n",
    "    print(annot['subSpanType'])\n",
    "    print(annot['subSpan'][0],annot['subSpan'][1])\n",
    "    subSpanRange = list(range(annot['subSpan'][0],annot['subSpan'][1]))\n",
    "    # print(subSpanRange)\n",
    "    subSpanIds = []\n",
    "    subSpanLabels = []\n",
    "    for id, label, startChar in zip(demo_ids, demo_labels, demo_token_startchar):\n",
    "        if startChar in subSpanRange:\n",
    "            subSpanIds.append(id)\n",
    "            subSpanLabels.append(label)\n",
    "    print(subSpanIds)\n",
    "    print(subSpanLabels)\n",
    "    print(tokenizer.decode(subSpanIds,skip_special_tokens=True))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'levels in the subject sample were decreased to 63% of control value'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_txt[demo_doc][1391:1458]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/cs_roberta_base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "class Stage1model(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(Stage1model, self).__init__()\n",
    "        self.mod = RobertaModel.from_pretrained(\n",
    "                    model_name,\n",
    "                    num_labels=num_classes+1,\n",
    "                    hidden_dropout_prob=dropout,\n",
    "                    output_hidden_states=True)\n",
    "        self.norm = nn.BatchNorm1d(512, eps=self.mod.config.layer_norm_eps)\n",
    "        self.drop = nn.Dropout(self.mod.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.mod.config.hidden_size, num_classes+1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.mod(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        y_hat = output.hidden_states[-1]\n",
    "        y_hat = self.norm(y_hat)\n",
    "        y_hat = self.drop(y_hat)\n",
    "        y_hat = self.classifier(y_hat).permute(0,2,1)\n",
    "        return y_hat\n",
    "\n",
    "model = Stage1model().to(device)\n",
    "\n",
    "model_new = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stage1model(\n",
       "  (mod): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class OurBERTModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(OurBERTModel, self).__init__()\n",
    "#         self.mod = AutoModel.from_pretrained(model_name, num_labels=num_classes+1)\n",
    "#         self.drop = nn.Dropout(self.mod.config.hidden_dropout_prob)\n",
    "#         self.classifier = nn.Linear(self.mod.config.hidden_size, num_classes+1)\n",
    "\n",
    "#     def forward(self, text, att_mask):\n",
    "#         b, num_tokens = text.shape\n",
    "#         token_type = torch.zeros((b, num_tokens), dtype=torch.long).to(device)\n",
    "#         outputs = self.mod(text, attention_mask=att_mask, token_type_ids=token_type)\n",
    "#         return self.classifier(self.drop(outputs['last_hidden_state']))\n",
    "\n",
    "# model = OurBERTModel().to(device)\n",
    "\n",
    "# model_old = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_logits = model(demo_batch['input_ids'], demo_batch['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_logits.permute(0,2,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_batch['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ypred = []\n",
    "# ytrue = []\n",
    "# for dlabels, dlogits in zip(demo_batch['labels'], demo_logits.permute(0,2,1)):\n",
    "#     print(dlabels.shape)\n",
    "#     print(dlogits.shape)\n",
    "#     for tlogits, tlabels in zip(dlogits, dlabels):\n",
    "#         print(tlabels.shape)\n",
    "#         print(tlogits.shape)\n",
    "#         ypred.append(tlogits.argmax().item())\n",
    "#         ytrue.append(tlabels.item())\n",
    "#         print(ypred)\n",
    "#         print(ytrue)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_training_steps = n_epochs * len(batched_train_ds)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=n_training_steps\n",
    ")\n",
    "\n",
    "\n",
    "def train_epoch(ds, criterion):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    for idx, batch in enumerate(ds):\n",
    "\n",
    "        labels = batch['labels']\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        # loss = (loss * attention_mask).sum() / (attention_mask).sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "            \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "\n",
    "def eval_epoch(ds, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(ds):\n",
    "\n",
    "            labels = batch['labels']\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            # loss = (loss * attention_mask).sum() / (attention_mask).sum()\n",
    "\n",
    "            for dlogits, dlabels in zip(logits.permute(0,2,1), labels):\n",
    "                    for tlogits, tlabels in zip(dlogits, dlabels):\n",
    "                        ypred.append(tlogits.argmax().item())\n",
    "                        ytrue.append(tlabels.item())\n",
    "\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    acc = metrics.accuracy_score(ytrue,ypred)\n",
    "    report = classification_report(ytrue,ypred,\n",
    "                                    labels=list(task_map.values()),\n",
    "                                    target_names=list(task_map.keys()),\n",
    "                                    output_dict=True,\n",
    "                                    zero_division=0)\n",
    "\n",
    "                                    \n",
    "\n",
    "    return loss.item(), acc, report, ytrue, ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8f58925d154b8ea37d679edab1c1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/730 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Begin Epoch 1 ============\n",
      "Train loss: 425.7706298828125\n",
      "Eval on train set loss: 422.37054443359375   accuracy: 0.9551341062898089\n",
      "Eval on dev set loss: 1009.04296875   accuracy: 0.9577690972222223\n",
      "============ Begin Epoch 2 ============\n",
      "Train loss: 270.84747314453125\n",
      "Eval on train set loss: 259.2937927246094   accuracy: 0.9663241441082803\n",
      "Eval on dev set loss: 668.6246337890625   accuracy: 0.9637369791666667\n",
      "============ Begin Epoch 3 ============\n",
      "Train loss: 211.243408203125\n",
      "Eval on train set loss: 187.7240753173828   accuracy: 0.9719533738057324\n",
      "Eval on dev set loss: 629.1467895507812   accuracy: 0.9660807291666667\n",
      "============ Begin Epoch 4 ============\n",
      "Train loss: 149.69638061523438\n",
      "Eval on train set loss: 139.66604614257812   accuracy: 0.9773213574840764\n",
      "Eval on dev set loss: 584.3868408203125   accuracy: 0.9674045138888889\n",
      "============ Begin Epoch 5 ============\n",
      "Train loss: 122.36125183105469\n",
      "Eval on train set loss: 117.50112915039062   accuracy: 0.9815510549363057\n",
      "Eval on dev set loss: 595.32666015625   accuracy: 0.967578125\n",
      "============ Begin Epoch 6 ============\n",
      "Train loss: 112.48676300048828\n",
      "Eval on train set loss: 98.48626708984375   accuracy: 0.9847793093152867\n",
      "Eval on dev set loss: 599.6752319335938   accuracy: 0.9685112847222223\n",
      "============ Begin Epoch 7 ============\n",
      "Train loss: 103.50200653076172\n",
      "Eval on train set loss: 87.07694244384766   accuracy: 0.9865333897292994\n",
      "Eval on dev set loss: 605.7376098632812   accuracy: 0.9669270833333333\n",
      "============ Begin Epoch 8 ============\n",
      "Train loss: 101.3952865600586\n",
      "Eval on train set loss: 75.36235046386719   accuracy: 0.9890836484872612\n",
      "Eval on dev set loss: 623.478515625   accuracy: 0.9700737847222223\n",
      "============ Begin Epoch 9 ============\n",
      "Train loss: 83.32720947265625\n",
      "Eval on train set loss: 64.48963928222656   accuracy: 0.9905578224522293\n",
      "Eval on dev set loss: 607.099365234375   accuracy: 0.9691623263888889\n",
      "============ Begin Epoch 10 ============\n",
      "Train loss: 83.77423095703125\n",
      "Eval on train set loss: 61.31974411010742   accuracy: 0.9906138037420382\n",
      "Eval on dev set loss: 614.9817504882812   accuracy: 0.9681423611111111\n"
     ]
    }
   ],
   "source": [
    "run_report = {  'epoch':[],\n",
    "                'train_loss':[],\n",
    "                'eval_train_loss':[],\n",
    "                'eval_train_acc':[],\n",
    "                'eval_train_ytrue':[],\n",
    "                'eval_train_ypred':[],\n",
    "                'eval_train_rpt':[],\n",
    "                'eval_dev_loss':[],\n",
    "                'eval_dev_acc':[],\n",
    "                'eval_dev_ytrue':[],\n",
    "                'eval_dev_ypred':[],\n",
    "                'eval_dev_rpt':[],\n",
    "             }\n",
    "\n",
    "num_total_steps = n_epochs * (len(batched_train_ds) * 2 + len(batched_dev_ds))\n",
    "progress_bar = tqdm(range(num_total_steps))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    run_report['epoch'].append(epoch)\n",
    "    \n",
    "    print(f\"============ Begin Epoch {epoch+1} ============\")\n",
    "\n",
    "    loss = train_epoch(batched_train_ds, criterion)\n",
    "    print(f\"Train loss: {loss}\")\n",
    "    run_report['train_loss'].append(loss)\n",
    "    \n",
    "    output = eval_epoch(batched_train_ds, criterion)\n",
    "    (loss, acc, report, ytrue, ypred) = output\n",
    "    print(f'Eval on train set loss: {loss}   accuracy: {acc}')\n",
    "    run_report['eval_train_loss'].append(loss)\n",
    "    run_report['eval_train_acc'].append(acc)\n",
    "    run_report['eval_train_ytrue'].append(ytrue)\n",
    "    run_report['eval_train_ypred'].append(ypred)\n",
    "    run_report['eval_train_rpt'].append(report)\n",
    "\n",
    "    output = eval_epoch(batched_dev_ds, criterion)\n",
    "    (loss, acc, report, ytrue, ypred) = output\n",
    "    print(f'Eval on dev set loss: {loss}   accuracy: {acc}')\n",
    "    run_report['eval_dev_loss'].append(loss)\n",
    "    run_report['eval_dev_acc'].append(acc)\n",
    "    run_report['eval_dev_ytrue'].append(ytrue)\n",
    "    run_report['eval_dev_ypred'].append(ypred)\n",
    "    run_report['eval_dev_rpt'].append(report)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98803833 0.00286341 0.00168572 0.00602702 0.00138552]\n",
      " [0.05147679 0.93164557 0.00253165 0.01097046 0.00337553]\n",
      " [0.24528302 0.04528302 0.44339623 0.19245283 0.07358491]\n",
      " [0.26577181 0.02281879 0.15704698 0.54496644 0.00939597]\n",
      " [0.40952381 0.04761905 0.07619048 0.21269841 0.25396825]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_labels = list(task_map.keys())\n",
    "display_labels.insert(0,str('NoLabel'))\n",
    "cm = confusion_matrix(ytrue,ypred,normalize='true')\n",
    "#cm = confusion_matrix(ytrue,ypred)\n",
    "print(cm)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=display_labels).plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42787,   124,    73,   261,    60],\n",
       "       [   61,  1104,     3,    13,     4],\n",
       "       [  130,    24,   235,   102,    39],\n",
       "       [  198,    17,   117,   406,     7],\n",
       "       [  129,    15,    24,    67,    80]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_metrics(reports):\n",
    "    metrics = []\n",
    "    for epoch in reports:\n",
    "        # print(epoch)\n",
    "        epoch_metrics = {}\n",
    "        for task, rpt in task_map.items():\n",
    "            for metric, value in epoch[task].items():\n",
    "                epoch_metrics[str(task+'_'+metric)] = value\n",
    "        metrics.append(epoch_metrics)\n",
    "\n",
    "    metrics = pd.DataFrame.from_dict(metrics)\n",
    "    metrics.index.rename('epoch')\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity_precision</th>\n",
       "      <th>Quantity_recall</th>\n",
       "      <th>Quantity_f1-score</th>\n",
       "      <th>Quantity_support</th>\n",
       "      <th>MeasuredProperty_precision</th>\n",
       "      <th>MeasuredProperty_recall</th>\n",
       "      <th>MeasuredProperty_f1-score</th>\n",
       "      <th>MeasuredProperty_support</th>\n",
       "      <th>MeasuredEntity_precision</th>\n",
       "      <th>MeasuredEntity_recall</th>\n",
       "      <th>MeasuredEntity_f1-score</th>\n",
       "      <th>MeasuredEntity_support</th>\n",
       "      <th>Qualifier_precision</th>\n",
       "      <th>Qualifier_recall</th>\n",
       "      <th>Qualifier_f1-score</th>\n",
       "      <th>Qualifier_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.812655</td>\n",
       "      <td>0.882695</td>\n",
       "      <td>0.846228</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.871859</td>\n",
       "      <td>0.932169</td>\n",
       "      <td>0.901006</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.609865</td>\n",
       "      <td>0.318688</td>\n",
       "      <td>0.418623</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.563544</td>\n",
       "      <td>0.344902</td>\n",
       "      <td>0.427912</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.893572</td>\n",
       "      <td>0.949183</td>\n",
       "      <td>0.920538</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.599853</td>\n",
       "      <td>0.478617</td>\n",
       "      <td>0.532421</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.620890</td>\n",
       "      <td>0.497366</td>\n",
       "      <td>0.552306</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.894791</td>\n",
       "      <td>0.976718</td>\n",
       "      <td>0.933961</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.594090</td>\n",
       "      <td>0.671353</td>\n",
       "      <td>0.630363</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.672419</td>\n",
       "      <td>0.639913</td>\n",
       "      <td>0.655764</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.763514</td>\n",
       "      <td>0.087869</td>\n",
       "      <td>0.157601</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.912555</td>\n",
       "      <td>0.981195</td>\n",
       "      <td>0.945631</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.627396</td>\n",
       "      <td>0.786175</td>\n",
       "      <td>0.697868</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.723255</td>\n",
       "      <td>0.735358</td>\n",
       "      <td>0.729256</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.713748</td>\n",
       "      <td>0.294712</td>\n",
       "      <td>0.417171</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.930400</td>\n",
       "      <td>0.984553</td>\n",
       "      <td>0.956711</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.651902</td>\n",
       "      <td>0.853544</td>\n",
       "      <td>0.739219</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.800663</td>\n",
       "      <td>0.748063</td>\n",
       "      <td>0.773470</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.806154</td>\n",
       "      <td>0.407465</td>\n",
       "      <td>0.541322</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.972334</td>\n",
       "      <td>0.975599</td>\n",
       "      <td>0.973964</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.672840</td>\n",
       "      <td>0.893966</td>\n",
       "      <td>0.767799</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.776308</td>\n",
       "      <td>0.836690</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.786031</td>\n",
       "      <td>0.551322</td>\n",
       "      <td>0.648080</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.979642</td>\n",
       "      <td>0.980300</td>\n",
       "      <td>0.979971</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.810520</td>\n",
       "      <td>0.839484</td>\n",
       "      <td>0.824748</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.842222</td>\n",
       "      <td>0.822126</td>\n",
       "      <td>0.832053</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.909337</td>\n",
       "      <td>0.522551</td>\n",
       "      <td>0.663704</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.977293</td>\n",
       "      <td>0.982762</td>\n",
       "      <td>0.980020</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.846108</td>\n",
       "      <td>0.834212</td>\n",
       "      <td>0.840118</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.847422</td>\n",
       "      <td>0.876046</td>\n",
       "      <td>0.861496</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.643079</td>\n",
       "      <td>0.736748</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.974535</td>\n",
       "      <td>0.985225</td>\n",
       "      <td>0.979851</td>\n",
       "      <td>4467</td>\n",
       "      <td>0.822554</td>\n",
       "      <td>0.871705</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>1707</td>\n",
       "      <td>0.834248</td>\n",
       "      <td>0.895259</td>\n",
       "      <td>0.863677</td>\n",
       "      <td>3227</td>\n",
       "      <td>0.827619</td>\n",
       "      <td>0.675739</td>\n",
       "      <td>0.744007</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quantity_precision  Quantity_recall  Quantity_f1-score  Quantity_support  \\\n",
       "0            0.812655         0.882695           0.846228              4467   \n",
       "1            0.871859         0.932169           0.901006              4467   \n",
       "2            0.893572         0.949183           0.920538              4467   \n",
       "3            0.894791         0.976718           0.933961              4467   \n",
       "4            0.912555         0.981195           0.945631              4467   \n",
       "5            0.930400         0.984553           0.956711              4467   \n",
       "6            0.972334         0.975599           0.973964              4467   \n",
       "7            0.979642         0.980300           0.979971              4467   \n",
       "8            0.977293         0.982762           0.980020              4467   \n",
       "9            0.974535         0.985225           0.979851              4467   \n",
       "\n",
       "   MeasuredProperty_precision  MeasuredProperty_recall  \\\n",
       "0                    0.000000                 0.000000   \n",
       "1                    0.609865                 0.318688   \n",
       "2                    0.599853                 0.478617   \n",
       "3                    0.594090                 0.671353   \n",
       "4                    0.627396                 0.786175   \n",
       "5                    0.651902                 0.853544   \n",
       "6                    0.672840                 0.893966   \n",
       "7                    0.810520                 0.839484   \n",
       "8                    0.846108                 0.834212   \n",
       "9                    0.822554                 0.871705   \n",
       "\n",
       "   MeasuredProperty_f1-score  MeasuredProperty_support  \\\n",
       "0                   0.000000                      1707   \n",
       "1                   0.418623                      1707   \n",
       "2                   0.532421                      1707   \n",
       "3                   0.630363                      1707   \n",
       "4                   0.697868                      1707   \n",
       "5                   0.739219                      1707   \n",
       "6                   0.767799                      1707   \n",
       "7                   0.824748                      1707   \n",
       "8                   0.840118                      1707   \n",
       "9                   0.846416                      1707   \n",
       "\n",
       "   MeasuredEntity_precision  MeasuredEntity_recall  MeasuredEntity_f1-score  \\\n",
       "0                  0.000000               0.000000                 0.000000   \n",
       "1                  0.563544               0.344902                 0.427912   \n",
       "2                  0.620890               0.497366                 0.552306   \n",
       "3                  0.672419               0.639913                 0.655764   \n",
       "4                  0.723255               0.735358                 0.729256   \n",
       "5                  0.800663               0.748063                 0.773470   \n",
       "6                  0.776308               0.836690                 0.805369   \n",
       "7                  0.842222               0.822126                 0.832053   \n",
       "8                  0.847422               0.876046                 0.861496   \n",
       "9                  0.834248               0.895259                 0.863677   \n",
       "\n",
       "   MeasuredEntity_support  Qualifier_precision  Qualifier_recall  \\\n",
       "0                    3227             0.000000          0.000000   \n",
       "1                    3227             0.000000          0.000000   \n",
       "2                    3227             0.625000          0.007776   \n",
       "3                    3227             0.763514          0.087869   \n",
       "4                    3227             0.713748          0.294712   \n",
       "5                    3227             0.806154          0.407465   \n",
       "6                    3227             0.786031          0.551322   \n",
       "7                    3227             0.909337          0.522551   \n",
       "8                    3227             0.862357          0.643079   \n",
       "9                    3227             0.827619          0.675739   \n",
       "\n",
       "   Qualifier_f1-score  Qualifier_support  \n",
       "0            0.000000               1286  \n",
       "1            0.000000               1286  \n",
       "2            0.015361               1286  \n",
       "3            0.157601               1286  \n",
       "4            0.417171               1286  \n",
       "5            0.541322               1286  \n",
       "6            0.648080               1286  \n",
       "7            0.663704               1286  \n",
       "8            0.736748               1286  \n",
       "9            0.744007               1286  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_metrics = tabulate_metrics(run_report['eval_train_rpt'])\n",
    "train_set_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity_precision</th>\n",
       "      <th>Quantity_recall</th>\n",
       "      <th>Quantity_f1-score</th>\n",
       "      <th>Quantity_support</th>\n",
       "      <th>MeasuredProperty_precision</th>\n",
       "      <th>MeasuredProperty_recall</th>\n",
       "      <th>MeasuredProperty_f1-score</th>\n",
       "      <th>MeasuredProperty_support</th>\n",
       "      <th>MeasuredEntity_precision</th>\n",
       "      <th>MeasuredEntity_recall</th>\n",
       "      <th>MeasuredEntity_f1-score</th>\n",
       "      <th>MeasuredEntity_support</th>\n",
       "      <th>Qualifier_precision</th>\n",
       "      <th>Qualifier_recall</th>\n",
       "      <th>Qualifier_f1-score</th>\n",
       "      <th>Qualifier_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.797498</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.827922</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843307</td>\n",
       "      <td>0.903797</td>\n",
       "      <td>0.872505</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.475962</td>\n",
       "      <td>0.186792</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>530</td>\n",
       "      <td>0.407960</td>\n",
       "      <td>0.220134</td>\n",
       "      <td>0.285963</td>\n",
       "      <td>745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.864032</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>0.892245</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.484472</td>\n",
       "      <td>0.294340</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>530</td>\n",
       "      <td>0.433396</td>\n",
       "      <td>0.310067</td>\n",
       "      <td>0.361502</td>\n",
       "      <td>745</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.945148</td>\n",
       "      <td>0.888536</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.485232</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.458167</td>\n",
       "      <td>530</td>\n",
       "      <td>0.467041</td>\n",
       "      <td>0.446980</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>745</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.832468</td>\n",
       "      <td>0.947679</td>\n",
       "      <td>0.886346</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.472998</td>\n",
       "      <td>0.479245</td>\n",
       "      <td>0.476101</td>\n",
       "      <td>530</td>\n",
       "      <td>0.475871</td>\n",
       "      <td>0.476510</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>745</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.136508</td>\n",
       "      <td>0.209246</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.839219</td>\n",
       "      <td>0.942616</td>\n",
       "      <td>0.887917</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.515094</td>\n",
       "      <td>0.497721</td>\n",
       "      <td>530</td>\n",
       "      <td>0.509404</td>\n",
       "      <td>0.436242</td>\n",
       "      <td>0.469993</td>\n",
       "      <td>745</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.244604</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.865492</td>\n",
       "      <td>0.912236</td>\n",
       "      <td>0.888250</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.458882</td>\n",
       "      <td>0.526415</td>\n",
       "      <td>0.490334</td>\n",
       "      <td>530</td>\n",
       "      <td>0.465455</td>\n",
       "      <td>0.515436</td>\n",
       "      <td>0.489172</td>\n",
       "      <td>745</td>\n",
       "      <td>0.449367</td>\n",
       "      <td>0.225397</td>\n",
       "      <td>0.300211</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.865446</td>\n",
       "      <td>0.917300</td>\n",
       "      <td>0.890619</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.556650</td>\n",
       "      <td>0.426415</td>\n",
       "      <td>0.482906</td>\n",
       "      <td>530</td>\n",
       "      <td>0.541872</td>\n",
       "      <td>0.442953</td>\n",
       "      <td>0.487445</td>\n",
       "      <td>745</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.227848</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.860630</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>0.890428</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.554987</td>\n",
       "      <td>0.409434</td>\n",
       "      <td>0.471227</td>\n",
       "      <td>530</td>\n",
       "      <td>0.508541</td>\n",
       "      <td>0.519463</td>\n",
       "      <td>0.513944</td>\n",
       "      <td>745</td>\n",
       "      <td>0.437086</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.931646</td>\n",
       "      <td>0.894289</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.519912</td>\n",
       "      <td>0.443396</td>\n",
       "      <td>0.478615</td>\n",
       "      <td>530</td>\n",
       "      <td>0.478210</td>\n",
       "      <td>0.544966</td>\n",
       "      <td>0.509410</td>\n",
       "      <td>745</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quantity_precision  Quantity_recall  Quantity_f1-score  Quantity_support  \\\n",
       "0            0.797498         0.860759           0.827922              1185   \n",
       "1            0.843307         0.903797           0.872505              1185   \n",
       "2            0.864032         0.922363           0.892245              1185   \n",
       "3            0.838323         0.945148           0.888536              1185   \n",
       "4            0.832468         0.947679           0.886346              1185   \n",
       "5            0.839219         0.942616           0.887917              1185   \n",
       "6            0.865492         0.912236           0.888250              1185   \n",
       "7            0.865446         0.917300           0.890619              1185   \n",
       "8            0.860630         0.922363           0.890428              1185   \n",
       "9            0.859813         0.931646           0.894289              1185   \n",
       "\n",
       "   MeasuredProperty_precision  MeasuredProperty_recall  \\\n",
       "0                    0.000000                 0.000000   \n",
       "1                    0.475962                 0.186792   \n",
       "2                    0.484472                 0.294340   \n",
       "3                    0.485232                 0.433962   \n",
       "4                    0.472998                 0.479245   \n",
       "5                    0.481481                 0.515094   \n",
       "6                    0.458882                 0.526415   \n",
       "7                    0.556650                 0.426415   \n",
       "8                    0.554987                 0.409434   \n",
       "9                    0.519912                 0.443396   \n",
       "\n",
       "   MeasuredProperty_f1-score  MeasuredProperty_support  \\\n",
       "0                   0.000000                       530   \n",
       "1                   0.268293                       530   \n",
       "2                   0.366197                       530   \n",
       "3                   0.458167                       530   \n",
       "4                   0.476101                       530   \n",
       "5                   0.497721                       530   \n",
       "6                   0.490334                       530   \n",
       "7                   0.482906                       530   \n",
       "8                   0.471227                       530   \n",
       "9                   0.478615                       530   \n",
       "\n",
       "   MeasuredEntity_precision  MeasuredEntity_recall  MeasuredEntity_f1-score  \\\n",
       "0                  0.000000               0.000000                 0.000000   \n",
       "1                  0.407960               0.220134                 0.285963   \n",
       "2                  0.433396               0.310067                 0.361502   \n",
       "3                  0.467041               0.446980                 0.456790   \n",
       "4                  0.475871               0.476510                 0.476190   \n",
       "5                  0.509404               0.436242                 0.469993   \n",
       "6                  0.465455               0.515436                 0.489172   \n",
       "7                  0.541872               0.442953                 0.487445   \n",
       "8                  0.508541               0.519463                 0.513944   \n",
       "9                  0.478210               0.544966                 0.509410   \n",
       "\n",
       "   MeasuredEntity_support  Qualifier_precision  Qualifier_recall  \\\n",
       "0                     745             0.000000          0.000000   \n",
       "1                     745             0.000000          0.000000   \n",
       "2                     745             0.250000          0.003175   \n",
       "3                     745             0.300000          0.028571   \n",
       "4                     745             0.447917          0.136508   \n",
       "5                     745             0.500000          0.161905   \n",
       "6                     745             0.449367          0.225397   \n",
       "7                     745             0.562500          0.142857   \n",
       "8                     745             0.437086          0.209524   \n",
       "9                     745             0.421053          0.253968   \n",
       "\n",
       "   Qualifier_f1-score  Qualifier_support  \n",
       "0            0.000000                315  \n",
       "1            0.000000                315  \n",
       "2            0.006270                315  \n",
       "3            0.052174                315  \n",
       "4            0.209246                315  \n",
       "5            0.244604                315  \n",
       "6            0.300211                315  \n",
       "7            0.227848                315  \n",
       "8            0.283262                315  \n",
       "9            0.316832                315  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set_metrics = tabulate_metrics(run_report['eval_dev_rpt'])\n",
    "dev_set_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## loss plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['eval_dev_loss'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## accuracy plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['eval_dev_acc'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('measeval')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "855fd3a08a97af1244f675d4c07eb3dc075792e0eef5adc33d42e4b83be782b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
